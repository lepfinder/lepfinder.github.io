{"meta":{"title":"XiYang's Blog","subtitle":"让一切慢下来，体验周边的美好","description":null,"author":"XiYang","url":"http://yoursite.com"},"pages":[{"title":"关于我","date":"2017-09-14T01:22:03.000Z","updated":"2017-09-14T01:56:26.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"Name &amp; 联系方式 name：解西扬 telPhone：13220100526 qq：80381107 经历 2007-2011 山东理工大学 2011-2013 北大方正电子科技有限公司 2013-2014 百度糯米 2014至今 北京千丁互联科技有限公司 专注于 java 领域开发，对分布式系统开发和设计有一定的经验，主导设计开发过当前公司的订单、促销、商城、支付、财务结算和风控等系统。 擅于总结，创造轮子，提供了一些效率工具，比如代码生成器、集中式导出服务、通用监控报警平台等。"},{"title":"个人项目","date":"2017-09-14T01:30:29.000Z","updated":"2017-09-15T06:28:04.000Z","comments":true,"path":"project/index.html","permalink":"http://yoursite.com/project/index.html","excerpt":"","text":"工作时间久了，对于重复性的工作越来越排斥，本页面记录了一些在工作中创造的一些轮子，等轮子多了，再开发就是一些积木的拼搭了。 代码生成器概述codeg是一个轻量级的代码生成器内核（代码仅300行左右），基于Python和jinja2开发，你可以定制自己的项目模板，快速生成可以直接运行的工程项目。项目主页： github 功能特点 根据数据库连接配置可以支持直接生成java工程 支持生成指定表的工程代码 支持读取数据库表注释，自动完成java类注释 微框架设计，方便自己修改模板完成自己的重复性代码工作 DBMaster介绍dbmaster是一个python编写的在线数据库查询客户端，可以有效隔离线上数据库环境，提供了一系列便于开发者使用的特性。操作体验尽量兼容navcat。项目主页：github 特性 支持SQL语法高亮和自动提示 支持SQL格式化 支持执行选中的SQL片段 支持数据库SCHEMA显示和表结构信息（双击表名显示表结构信息） 支持快捷键执行，Cmd+R/Ctrl+R执行SQL 支持查询执行记录 支持多个语句同时执行，显示多个result结果集 Knight什么是 KnightKnight 是一个 Java 开发的WEB后台开发微框架，基于成熟的 Spring 、 MyBatis 后端框架，集成AngularJS、echart等一些前端框架，可以极大的简化日常的后台开发。 特性 提供文件导出服务，配置式开发 提供简单的页面自动渲染能力，根据配置，自动生成搜索区域和table数据 集成echart，提供报表工具，可以支持简易的报表渲染功能 配置文件提供历史版本记录，可以在线查看diff 提供易用的debug信息，可以支持查看导出的sql和页面渲染使用的sql 支持动态多数据源，可以动态添加、删除和修改数据源配置 数据源类型支持mysql、hive 导出支持本地字典配置，可以省略大量的case when的写法 为什么要用 KnightKnight的设计初衷是为了支持集中式的文件导出服务，用以解决后台文件导出的需求。经过一系列的迭代之后Knight的目标将会是简化前后端的开发。抽象出后台通用功能，封装前后端流程。提供配置式开发方式，提高开发效率，节省开发成本，规范前后端的写法。 针对于导出需求，无需编写后端代码，只需在配置中心进行简单的配置后，在前端接入导出即可完成开发。导出的字段完全自定义，需求变更也无需上线即可完成修改。针对于普通的页面需求，提供了前端指令可以动态生成搜索框和数据表格，无需编写后台代码，只需在配置中心进行配置即可。页面增减字段也无需上线，只需要修改配置即可。针对于报表需求，集成了echart，后端配置后前端即可通过指令渲染。提供易用的debug功能，可以在页面查看后台执行的sql及出错信息，无需频繁登录服务器查看日志。 Wukong简介wukong是一个独立开发的业务监控系统，提供对线上业务进行监控和报警的能力，可以由各业务开发人员根据产品和业务需求制定规则，当系统出现异常数据时及时通知给相应的责任人。 设计目的 线上业务异常反馈不及时，有些甚至几天后才会发现，导致修复特别困难。 整合监控功能，提供业务代码中嵌入异常报警的功能，进一步提高系统稳定性。 提供基础的报警组件，避免各系统重复开发，重复发明轮子。 具体适应的场景业务规则监控 支付系统支付成功了是否订单系统状态也是已支付 订单5分钟之后超时，是否有订单5分钟之后还没有超时 物业费收款成功，通知龙湖没有返回收据号 支付系统支付金额和订单应付金额不一致 订单平台和业态订单状态不一致 支付系统和订单平台支付状态不一致 券分号可用数量低于某个值报警 积分发送异常 开发者程序埋点异常上报开发者在开发过程中，主动埋点，在触发了某种异常之后，主动通知开发者。比如： 当系统无法连接redis，通知开发者 某个逻辑需要某个文件，当文件没有成功生成，触发报警。"},{"title":"tags","date":"2017-09-14T01:41:48.000Z","updated":"2017-09-14T01:42:05.000Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2017-09-14T01:37:51.000Z","updated":"2017-09-14T01:40:55.000Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"深入解析 spring","slug":"read-深入解析-spring","date":"2017-09-24T16:00:00.000Z","updated":"2017-09-25T10:46:18.000Z","comments":true,"path":"2017/09/25/read-深入解析-spring/","link":"","permalink":"http://yoursite.com2017/09/25/read-深入解析-spring/","excerpt":"","text":"spring 框架概述spring的 由来 和 使命 spring 是于2003年兴起的一个轻量级Java开发框架 由Rod Johnson在其著作 Expert One-On-One JeEE Development adn Design中阐述的部分理念和原型衍生而来 它最初的目的主要是为了简化Java EE的企业级应用开发 使命： 简化java开发 采取了以下4种关键策略 基于 POJO 的轻量级和最小侵入性编程 通过依赖注入和面向接口实现松耦合 基于切面和惯例进行声明式编程 通过切面和模板减少样板式代码 spring 框架概述Spring 包含了20多个模块，依照其所属功能可以划分为如下几个不同的功能模块。 另外一种展示方式 假如我们把 spring 的框架看成一颗树，最底层的 spring-core 和 容器工具类 构成了整个树的主干，所有上层的功能都依赖于这两个特性。 The Core Container consists of the spring-core, spring-beans, spring-context, spring-context-support, and spring-expression (Spring Expression Language) modules.The spring-core and spring-beans modules provide the fundamental parts of the framework, including the IoC and Dependency Injection features. 容器是Spring框架最核心的部分，它负责Spring应用中的Bean的创建、配置和管理。spring-core 和 spring-beans 模块提供了框架最基础的部分，包括IOC和DI特性支持。 Spring的IoC 容器什么是IoCIoC 的全称为：Inversion of Control，中文通常翻译为 ”控制反转“，还有一个别名叫做依赖注入（Dependency Injection）。 我们考虑一个电商流程下单的过程，对于创建订单的服务来讲，下单的过程描述的是这么一件事情： 记录谁在什么时候购买了哪些商品，使用了什么优惠，配送到何处。 前端传递给后台的参数通常只有： 会员ID 商品ID和数量 优惠券 配送地址ID 后端的服务接到请求后需要做如下的几件事情： 根据会员ID获取到会员详细的信息，比如会员姓名，会员手机号等 根据商品ID获取到商品的具体信息，价格、合同、供方 调用计价服务计算价格 记录用户的配送信息 将订单对象保存到数据库 我们可以看到一个下单服务依赖很多相关的服务，假如订单服务我们创建一个类叫 OrderService ，定义一个方法叫 makeOrder()。1234567891011121314151617public class OrderServiceImpl implements IOrderService &#123; private PassportService passportService; private ProductService productService; @Override public void makeOrder() &#123; //1. 获取会员信息 Member member = passportService.getMember(); //2. 获取商品信息 Product product = productService.getProduct(); &#125;&#125; 上述的代码中 OrderService 依赖 passportService 和 productService，如何完成这两个服务的初始化呢？ 假如不使用spring，可能我们需要写类似下面的代码1234567891011121314public OrderServiceImpl(PassportService passportService, ProductService productService) &#123; this.passportService = passportService; this.productService = productService;&#125;public static void main(String[] args) &#123; // 创建 PassportService 和 ProductService，并设置到orderService对象 PassportService passportService = new PassportService(); ProductService productService = new ProductService(); OrderServiceImpl orderService = new OrderServiceImpl(passportService,productService); orderService.makeOrder();&#125; 或使用 setter 的方法构建：123456789101112131415161718192021public void setPassportService(PassportService passportService) &#123; this.passportService = passportService;&#125;public void setProductService(ProductService productService) &#123; this.productService = productService;&#125;public static void main(String[] args) &#123; OrderServiceImpl orderService = new OrderServiceImpl(); // 创建 PassportService 和 ProductService，并设置到orderService对象 PassportService passportService = new PassportService(); ProductService productService = new ProductService(); orderService.setPassportService(passportService); orderService.setProductService(productService); orderService.makeOrder();&#125; 无论使用哪种方式，在实际的编码中都会非常的麻烦，一个类有的时候会依赖可能很多个其它类，如果全部是由程序员去控制类的初始化和依赖关系，将会是一件异常痛苦的事情。spring 通过IOC和DI，通过java本身的一些特性，很好的解决了这个问题。程序员无需再关心类的依赖，只需要在用到某个服务的时候声明一下即可，spring框架会帮助你注入所需的依赖。 spring 是如何知道依赖并完成依赖的注入呢，我们结合源码一点一点的看。 IoC 容器之BeanFactory首先我们要来探究容器的概念，所谓的容器是可以盛放东西的一类，在程序的世界中，我们经常会看到关于容器的存在，比如java容器类，通常也称为集合类。spring 中的容器类和其它的容器类有什么不同呢？ spring 提供了一个IoC容器，针对于其存储的对象可以管理其依赖关系，负责其所管理的bean的生命周期，从对象的创建到销毁。Spring 容器使用依赖注入（DI）来管理组成一个应用程序的组件，这些对象被称为 Spring Beans。 bean 是Spring中最核心的东西，因为Spring就像一个大水桶，而bean就像是容器里面的水，水桶脱离了水便也没有什么用处了。 在spring中，BeanFactory便是一个容器，里面的Bean便是其管理的对象。我们通过一个例子看看 spring BeanFactory 容器的用法。 一个例子首先定义一个bean如下：1234567package com.xiyang.study.spring4.bean;public class MyBeanTest &#123; public String sayHello(String name)&#123; return \"hello \"+name+\"!\"; &#125;&#125; 然后在配置文件中配置这个bean：1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd \" &gt; &lt;bean id=\"myBeanTest\" class=\"com.xiyang.study.spring4.bean.MyBeanTest\"&gt;&lt;/bean&gt;&lt;/beans&gt; 使用如下的测试代码测试它：123456789101112131415161718192021package com.xiyang.study.spring4;import com.xiyang.study.spring4.bean.MyBeanTest;import org.junit.Test;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.core.io.ClassPathResource;/** * Created by xiexiyang on 2017/9/25. */public class BeanFactoryTest &#123; @Test public void test()&#123; BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(\"beanTest.xml\")); MyBeanTest myBeanTest = (MyBeanTest) beanFactory.getBean(\"myBeanTest\"); String retVal = myBeanTest.sayHello(\"xiyang\"); System.out.println(retVal); &#125;&#125; 运行结果如下：可以看到，我们在测试用例中正确的拿到了 MyBeanTest 的实例，并执行了其中的 sayHello 方法。 说明：直接使用 BeanFactory 作为容器在日常的开发中并不多见，这里只是为了演示spring容器的用法，通常我们使用的是 ApplicationContext ，我们之后对他再做更详细的介绍。我们先来详细探究上上面的例子中到底发生了什么，spring 在其中又为我们做了什么？ 我们先自己猜想一下，假如让我们自己设计应该如何做呢？ 作为一个容器，首先我需要知道你想让我管理的类，你可以在xml中定义它并告诉我。我解析xml拿到你定义的bean对象，并将它实例化。将它放到我的容器中，如果要使用这个实例，可以通过我提供的getBean获取对应的bean，并调用这个bean的具体的某个方法。 源码剖析我们上面的猜想对不对呢？让我们从源码出发来一步一步的探究其本质，看如下测试用例的第一行代码：1BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(\"beanTest.xml\")); XmlBeanFactory首先我们初始化了一个 XmlBeanFactory ，这个对象是什么，能做什么呢？如下是 XmlBeanFactory 的类图： XmlBeanFactory 源码如下：12345678910111213141516171819202122232425262728public class XmlBeanFactory extends DefaultListableBeanFactory &#123; private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this); /** * Create a new XmlBeanFactory with the given resource, * which must be parsable using DOM. * @param resource XML resource to load bean definitions from * @throws BeansException in case of loading or parsing errors */ public XmlBeanFactory(Resource resource) throws BeansException &#123; this(resource, null); &#125; /** * Create a new XmlBeanFactory with the given input stream, * which must be parsable using DOM. * @param resource XML resource to load bean definitions from * @param parentBeanFactory parent bean factory * @throws BeansException in case of loading or parsing errors */ public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException &#123; super(parentBeanFactory); this.reader.loadBeanDefinitions(resource); &#125;&#125; XmlBeanFactory 自身的源码非常简单，只有两个构造函数和一个 XmlBeanDefinitionReader 的变量，由于XmlBeanFactory 继承自 DefaultListableBeanFactory。所以欲探究其本质，首先需要搞明白 DefaultListableBeanFactory 和 XmlBeanDefinitionReader这两个类。 XmlBeanDefinitionReader从名字上就可以看出 XmlBeanDefinitionReader 它是用来读取bean配置文件的一个类。我们从时序图上看一下spring解析配置文件的全过程： 上面的几个步骤如下：1、在XMLBeanFactory的构造函数中调用XmlBeanDefinitionReader的loadBeanDefinitions方法1234public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException &#123; super(parentBeanFactory); this.reader.loadBeanDefinitions(resource);&#125; 2、loadBeanDefinitions 读取文件并调用 doLoadBeanDefinitions12345678910111213public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; .... try &#123; InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; InputSource inputSource = new InputSource(inputStream); return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; &#125; ....&#125; 3、在doLoadBeanDefinitions中解析为Document，并调用registerBeanDefinitions方法1234567protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; Document doc = doLoadDocument(inputSource, resource); return registerBeanDefinitions(doc, resource); &#125;&#125; 4、registerBeanDefinitions 负责初始化 BeanDefinitionDocumentReader，调用其registerBeanDefinitions方法完成注册。1234567public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); documentReader.setEnvironment(this.getEnvironment()); int countBefore = getRegistry().getBeanDefinitionCount(); documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; 5、解析出root 节点调用doRegisterBeanDefinitions123456public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug(\"Loading bean definitions\"); Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root);&#125; 6、解析root节点，调用parseBeanDefinitions，解析bean12345678910protected void doRegisterBeanDefinitions(Element root) &#123; BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(this.readerContext, root, parent); preProcessXml(root); parseBeanDefinitions(root, this.delegate); postProcessXml(root); this.delegate = parent;&#125; 7、在parseBeanDefinitions中完成具体bean的解析12345678910111213141516171819202122protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; //解析默认的节点 parseDefaultElement(ele, delegate); &#125; else &#123; //解析自定义的节点 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 上面的代码逻辑还是比较清晰的，spring的xml配置中有两大类Bean的生命，一个是默认的，比如1&lt;bean id=\"myBeanTest\" class=\"com.xiyang.study.spring4.bean.MyBeanTest\"&gt;&lt;/bean&gt; 另一类是自定义的，比如1&lt;aop:aspectj-autoproxy proxy-target-class=\"true\"/&gt; 判断是否是默认的节点也很简单，就是那节点的namespaceUri 和 BEANS_NAMESPACE_URI做比较。12345public static final String BEANS_NAMESPACE_URI = \"http://www.springframework.org/schema/beans\";public boolean isDefaultNamespace(String namespaceUri) &#123; return (!StringUtils.hasLength(namespaceUri) || BEANS_NAMESPACE_URI.equals(namespaceUri));&#125; 默认标签的解析1234567891011121314151617181920// 根据不同的节点名称分别完成解析的过程private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; //对import标签的处理 if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; //对alias标签的处理 else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; //对bean标签的处理 else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; //对beans标签的处理 else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125;&#125; 自定义标签的解析Spring Bean最终我们解析出来的bean在spring容器中是以一个什么形式存在呢，我们来看 processBeanDefinition 方法的实现：12345678910111213141516protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; 可以看到我们最终拿到的是一个 BeanDefinitionHolder 类12345678910public class BeanDefinitionHolder implements BeanMetadataElement &#123; private final BeanDefinition beanDefinition; private final String beanName; private final String[] aliases; ....&#125; BeanDefinitionHolder 持有一个BeanDefinition 对象，其所拥有的属性和说明如下： class 这个属性是强制性的，并且指定用来创建 bean 的 bean 类。 name 这个属性指定唯一的 bean 标识符。在基于 XML 的配置元数据中，你可以使用 ID 和/或 name 属性来指定 bean 标识符。 scope 这个属性指定由特定的 bean 定义创建的对象的作用域，它将会在 bean 作用域的章节中进行讨论。 constructor-arg 它是用来注入依赖关系的，并会在接下来的章节中进行讨论。 properties 它是用来注入依赖关系的，并会在接下来的章节中进行讨论。 autowiring mode 它是用来注入依赖关系的，并会在接下来的章节中进行讨论。 lazy-initialization mode 延迟初始化的 bean 告诉 IoC 容器在它第一次被请求时，而不是在启动时去创建一个 bean 实例。 initialization 方法 在 bean 的所有必需的属性被容器设置之后，调用回调方法。它将会在 bean 的生命周期章节中进行讨论。 destruction 方法 当包含该 bean 的容器被销毁时，使用回调方法。它将会在 bean 的生命周期章节中进行讨论。 DefaultListableBeanFactoryDefaultListableBeanFactory 是 BeanFactory的一个具体实现，所以我们先来看 BeanFactory 接口定义的方法有哪些： IoC 容器之ApplicationContextBean 的加载 我们从上一节了解了 XmlBeanDefinitionReader 是如何读取配置文件并解析Bean的定义的，本节将关注一个 Bean 在 Spring 容器中是如何被加载和被初始化的。 Spring AOP 框架原理和实现Spring 事务管理","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/categories/读书笔记/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"spring 源码","slug":"spring-源码","permalink":"http://yoursite.com/tags/spring-源码/"}]},{"title":"每周札记","slug":"每周札记","date":"2017-09-24T16:00:00.000Z","updated":"2017-09-25T04:07:29.000Z","comments":true,"path":"2017/09/25/每周札记/","link":"","permalink":"http://yoursite.com2017/09/25/每周札记/","excerpt":"","text":"终身学习，保持兴趣。本文是一些日常学习和网上文章的记录。 博客国内技术团队博客 收录了国内各大技术公司官方技术博客 yikun 有一些高质量的博文，关于java 集合类的几篇文章值得一读 NeoRemind 研究生毕业于清华大学，本科毕业于北京邮电大学，目前工作在Hulu，从事Big data领域的研发工作，曾经在百度ECOM和程序化广告混迹6年，从事系统研发和架构工作，关注大数据、Web后端技术、广告系统技术以及致力于编写高质量的代码。曾在百度工作，写过一些很好的java相关的组件。作者发布的一些文章InfoQ – 谈谈后端业务系统的微服务化改造（http://www.infoq.com/cn/articles/the-back-end-business-systems-service-transformation）InfoQ聊聊架构 – 体系化认识RPC（http://mp.weixin.qq.com/s/lkz3zGk-KyMkI1eYeYH4ng）知乎专栏 – 深入解析Spark中的RPC（https://zhuanlan.zhihu.com/p/28893155） 江南白衣 spring side的作者 伍 翀（WuChong) 2008 - 2015 就读于北京理工大学。2015 年进入阿里巴巴中间件实时计算团队，JStorm 研发。2017 年加入计算平台，Blink/Flink 研发。 2017-09-25OmniGraffle 6/7 Axure7 注册码许可证 源码圈 365 胖友的书单整理 一些高质量的书籍推荐 Mybatis3.3.x技术内幕 关于MyBatis的源码深度分析，作者祖大俊，语言诙谐幽默，文章条理清晰。 pinpoint 技术概述 详解了pinpoint的一些设计思路，对于tracer系统的设计和了解有很大裨益 Java后端，应该日常翻看的中文技术网站 java后端博客和技术网站的推荐","categories":[],"tags":[{"name":"札记","slug":"札记","permalink":"http://yoursite.com/tags/札记/"}]},{"title":"深入解析 servlet","slug":"深入理解-servlet","date":"2017-09-20T16:00:00.000Z","updated":"2017-09-21T08:44:06.000Z","comments":true,"path":"2017/09/21/深入理解-servlet/","link":"","permalink":"http://yoursite.com2017/09/21/深入理解-servlet/","excerpt":"","text":"概述1. 什么是servlet Servlet 是基于 Java 技术的 web 组件，容器托管的，用于生成动态内容。可以被基于 Java 技术的 web server 动态加载并运行。客户端 通过 Servlet 容器实现的请求/应答模型与 Servlet 交互。 servlet 发展历史 123456789101112131415161718192021+=============+================+====================+=============================================================================+| VERSION | DATE | JAVA EE / JDK | FEATURES / CHANGES |+=============+================+====================+=============================================================================+| Servlet 3.1 | May 2013 | JavaEE 7 | Non-blocking I/O, HTTP protocol upgrade mechanism |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 3.0 | December 2009 | JavaEE 6, JavaSE 6 | Pluggability, Ease of development, Async Servlet, Security, File Uploading |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 2.5 | September 2005 | JavaEE 5, JavaSE 5 | Requires JavaSE 5, supports annotation |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 2.4 | November 2003 | J2EE 1.4, J2SE 1.3 | web.xml uses XML Schema |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 2.3 | August 2001 | J2EE 1.3, J2SE 1.2 | Addition of Filter |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 2.2 | August 1999 | J2EE 1.2, J2SE 1.2 | Becomes part of J2EE, introduced independent web applications in .war files |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 2.1 | November 1998 | Unspecified | First official specification, added RequestDispatcher, ServletContext |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 2.0 | | JDK 1.1 | Part of Java Servlet Development Kit 2.0 |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+| Servlet 1.0 | June 1997 | | |+-------------+----------------+--------------------+-----------------------------------------------------------------------------+ 2. 什么是servlet容器 Servlet 容器是 Web 服务器或应用程序服务器的一部分，用来提供发送 请求和响应 的网络服务，解码基于 MIME 的请求，并格式化基于 MIMIE 的响应。它包含和管理 servlets 的生命周期。 servlet 接口Servlet 接口是 Java Servlet API 的核心抽象。所有 Servlet 类必须直接或间接的实现该接口，或者更通常做法 是通过继承一个实现了该接口的类从而复用许多共性功能。目前有 GenericServlet 和 HttpServlet 这两个类实 现了 Servlet 接口。大多数情况下，开发者只需要继承 HttpServlet 去实现自己的 Servlet 即可。 servlet 相关的类图如下： Servlet 接口定义如下：（servlet 版本号 3.1.0） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package javax.servlet;import java.io.IOException;/** * Defines methods that all servlets must implement. * * &lt;p&gt;A servlet is a small Java program that runs within a Web server. * Servlets receive and respond to requests from Web clients, * usually across HTTP, the HyperText Transfer Protocol. * * &lt;p&gt;To implement this interface, you can write a generic servlet * that extends * &lt;code&gt;javax.servlet.GenericServlet&lt;/code&gt; or an HTTP servlet that * extends &lt;code&gt;javax.servlet.http.HttpServlet&lt;/code&gt;. * */public interface Servlet &#123; /** * Called by the servlet container to indicate to a servlet that the * servlet is being placed into service. * * &lt;p&gt;The servlet container calls the &lt;code&gt;init&lt;/code&gt; * method exactly once after instantiating the servlet. * The &lt;code&gt;init&lt;/code&gt; method must complete successfully * before the servlet can receive any requests. * */ public void init(ServletConfig config) throws ServletException; public ServletConfig getServletConfig(); /** * Called by the servlet container to allow the servlet to respond to * a request. * &lt;p&gt;This method is only called after the servlet's &lt;code&gt;init()&lt;/code&gt; * method has completed successfully. */ public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException; public String getServletInfo(); public void destroy();&#125; 2.1 请求处理方法Servlet 基础接口定义了用于客户端请求处理的 service 方法。当有请求到达时，该方法由 servlet 容器路由到一个 servlet 实例。Web 应用程序的并发请求处理通常需要 Web 开发人员去设计适合多线程执行的 Servlet，从而保证 service 方法能在一个特定时间点处理多线程并发执行。(注:即 Servlet 默认是线程不安全的，需要开发人员处理 多线程问题)通常 Web 容器对于并发请求将使用同一个 servlet 处理，并且在不同的线程中并发执行 service 方法。 2.2 Servlet 生命周期Servlet 是按照一个严格定义的生命周期被管理，该生命周期规定了 Servlet 如何被加载、实例化、初始化、 处理客户端请求，以及何时结束服务。该声明周期可以通过 javax.servlet.Servlet 接口中的 init、service 和 destroy 这些 API 来表示，所有 Servlet 必须直接或间接的实现 GenericServlet 或 HttpServlet 抽象类。 servlet的生命周期有四个阶段： 加载并实例化、初始化、请求处理、销毁。涉及到的方法有：init、service、destory等 加载并实例化Servlet容器负责加载和实例化Servelt。当Servlet容器启动时，或者在容器检测到需要这个Servlet来响应第一个请求时，创建Servlet实例。当Servlet容器启动后，Servlet通过类加载器来加载Servlet类，加载完成后再new一个Servlet对象来完成实例化。 初始化在Servlet实例化之后，容器将调用init（）方法，并传递实现ServletConfig接口的对象。在init（）方法中，Servlet可以部署描述符中读取配置参数，或者执行任何其他一次性活动。在Servlet的整个生命周期类，init（）方法只被调用一次。 请求处理当Servlet初始化后，容器就可以准备处理客户机请求了。当容器收到对这一Servlet的请求，就调用Servlet的service（）方法，并把请求和响应对象作为参数传递。当并行的请求到来时，多个service（）方法能够同时运行在独立的线程中。service()方法检查 HTTP 请求类型（GET、POST、PUT、DELETE 等），并在适当的时候调用 doGet()、doPost()、doPut()，doDelete() 等方法。 如下是HttpServlet里面service的实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException&#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125;&#125; 销毁一旦Servlet容器检测到一个Servlet要被卸载，这可能是因为要回收资源或者因为它正在被关闭，容器会在所有Servlet的service（）线程之后，调用Servlet的destroy（）方法。然后，Servlet就可以进行无用存储单元收集清理。这样Servlet对象就被销毁了。这四个阶段共同决定了Servlet的生命周期。 一个典型的处理过程请看如下的时序图： 请求的过程描述如下： Web Client 向Servlet容器（Tomcat）发出Http请求； Servlet容器接收Web Client的请求； Servlet容器创建一个HttpRequest对象，将Web Client请求的信息封装到这个对象中； Servlet容器创建一个HttpResponse对象； Servlet容器调用HttpServlet对象的service方法，把HttpRequest对象与HttpResponse对象作为参数传给 HttpServlet对象； HttpServlet调用HttpRequest对象的有关方法，获取Http请求信息； HttpServlet调用HttpResponse对象的有关方法，生成响应数据； Servlet容器把HttpServlet的响应结果传给Web Client； Servlet的框架是由两个Java包组成的：javax.servlet与javax.servlet.http。在javax.servlet包中定义了所有的Servlet类都必须实现或者扩展的通用接口和类。在javax.servlet.http包中定义了采用Http协议通信的HttpServlet类。Servlet的框架的核心是javax.servlet.Servlet接口，所有的Servlet都必须实现这个接口。在Servlet接口中定义了5个方法，其中3个方法代表了Servlet的生命周期： init(ServletConfig)方法：负责初始化Servlet对象，在Servlet的生命周期中，该方法执行一次；该方法执行在单线程的环境下，因此开发者不用考虑线程安全的问题；service(ServletRequest req,ServletResponse res)方法：负责响应客户的请求；为了提高效率，Servlet规范要求一个Servlet实例必须能够同时服务于多个客户端请求，即service()方法运行在多线程的环境下，Servlet开发者必须保证该方法的线程安全性；destroy()方法：当Servlet对象退出生命周期时，负责释放占用的资源； Servlet ContextServletContext(Servlet 上下文)接口定义了 servlet 运行在的 Web 应用的视图。容器供应商负责提供 Servlet 容器的 ServletContext 接口的实现。Servlet 可以使用 ServletContext 对象记录事件，获取 URL 引用的资源， 存取当前上下文的其他 Servlet 可以访问的属性。ServletContext 是 Web 服务器中已知路径的根。例如，Servlet 上下文可以从 http://www.mycorp.com/catalog 找出，/catalog 请求路径称为上下文路径，所有以它开头的请求都会被路由到与 ServletContext 相关联的 Web 应用。 Defines a set of methods that a servlet uses to communicate with its servlet container, for example, to get the MIME type of a file, dispatch requests, or write to a log file.There is one context per “web application” per Java Virtual Machine. (A “web application” is a collection of servlets and content installed under a specific subset of the server’s URL namespace such as /catalog and possibly installed via a .war file.) Servlet 中的 Listener整个 Tomcat 服务器中 Listener 使用的非常广泛，它是基于观察者模式设计的，Listener 的设计对开发 Servlet 应用程序提供了一种快捷的手段，能够方便的从另一个纵向维度控制程序和数据。目前 Servlet 中提供了 5 种两类事件的观察者接口，它们分别是： 4 个 EventListeners 类型的 ServletContextAttributeListener ServletRequestAttributeListener ServletRequestListener HttpSessionAttributeListener 2 个 LifecycleListeners 类型的 ServletContextListener HttpSessionListener 如下图所示： 它们基本上涵盖了整个 Servlet 生命周期中，你感兴趣的每种事件。这些 Listener 的实现类可以配置在 web.xml 中的 标签中。当然也可以在应用程序中动态添加 Listener，需要注意的是 ServletContextListener 在容器启动之后就不能再添加新的，因为它所监听的事件已经不会再出现。掌握这些 Listener 的使用，能够让我们的程序设计的更加灵活。 参考资料servlet 规范（3.1）可以去网上下载中英文文档 Java Servlet 3.1 规范笔记https://emacsist.github.io/emacsist/servlet/Java%20Servlet%203.1%20%E8%A7%84%E8%8C%83%E7%AC%94%E8%AE%B0.html#org7916fb9 Servlet 工作原理解析https://www.ibm.com/developerworks/cn/java/j-lo-servlet/ servlet的本质是什么，它是如何工作的？https://www.zhihu.com/question/21416727","categories":[{"name":"javaweb","slug":"javaweb","permalink":"http://yoursite.com/categories/javaweb/"}],"tags":[{"name":"servlet","slug":"servlet","permalink":"http://yoursite.com/tags/servlet/"}]},{"title":"深入解析springmvc","slug":"深入解析spring-MVC","date":"2017-09-20T16:00:00.000Z","updated":"2017-09-21T08:45:24.000Z","comments":true,"path":"2017/09/21/深入解析spring-MVC/","link":"","permalink":"http://yoursite.com2017/09/21/深入解析spring-MVC/","excerpt":"","text":"SpringMVC可以说是当前java web开发领域最流行的mvc框架了，了解其工作原理及设计思路对于开发者而言无疑有很大的益处。 众所周知，SpringMVC是建立在Servlet基础之上，一般来说配置所有的请求都由DispatcherServlet来处理，从web.xml的配置中就可以看出来。 12345678910111213141516&lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath*:spring-servlet.xml &lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;0&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;","categories":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/categories/spring/"}],"tags":[{"name":"springmvc","slug":"springmvc","permalink":"http://yoursite.com/tags/springmvc/"}]},{"title":"关于自建博客的一些东西","slug":"about-blog","date":"2017-09-19T01:37:28.000Z","updated":"2017-09-20T03:48:11.000Z","comments":true,"path":"2017/09/19/about-blog/","link":"","permalink":"http://yoursite.com2017/09/19/about-blog/","excerpt":"","text":"我日常的文档大部分是用markdown来管理的，日积月累也积攒了很多技术和非技术的文章。最常用的工具是sublime + markdown preview，基本上可以满足大部分日常文档的编写需求。但是大部分是一些草稿或记录，一直没有找到很好的博客解决方案，直到我发现了hexo。本文是我在日常编写文档和使用hexo搭建博客中使用到的一些工具。 markdown 简介markdown 现在已经成了我日常工作和学习的一部分了，惊艳于它简单的语法和自由的表达方式，让人沉浸于写作的乐趣，让人更专注与写作和技术本身。 基础语法可以参考 http://wowubuntu.com/markdown/。 hexo 简介 A fast, simple &amp; powerful blog framework Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 部署到哪里hexo 是一个本地的静态博客框架工具，可以将我们平时的文章渲染为最终的 html 代码，但是如何将文章放到公网上，让其它人也可以访问呢？当然可以买一个主机，自己搭建服务器。更为方便的是可以使用github来托管博客。 GitHub Pages 本用于介绍托管在GitHub的项目，不过，由于他的空间免费稳定，用来做搭建一个博客再好不过了。 简单的步骤： 申请 github page 配置hexo deploy 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/lepfinder/lepfinder.github.io.git branch: master 安装git 在本地blog目录执行发布 其它如何快速的在 markdown 文档中插入图片插图是编写文档必不可少的一个动作，如何快速的在markdown文本中插入图片呢？我本地使用 “Alfred 工作流 + 七牛云” 外链的方式。使用起来非常便捷： command + control + shift + 4 完成截图 command + control + shift + V 完成图片上传到七牛 command + V 粘贴外链地址到指定位置（如果光标此时在编辑器中，这一步其实是自动的） 具体使用方法参考 简化markdown写作中的贴图流程 如何画出好看的图？推荐 OmniGraffle，下面是一个截图： 如何在修改完文章后自动渲染推荐使用livereload，我使用的是lepture写的一个python的库，项目地址。livereload 可以做什么事情呢？比如作为一个前端开发，每次写完html或js代码之后，保存完，需要去浏览器手动刷新页面才能看到修改后的效果，能不能文件发生变化之后浏览器自动刷新呢，这样将会给实际的开发带来很大的便利，于是livereload便出场了。 使用步骤： 下载安装 server 端，即python-livereload 进入需要监控的地址，比如 12cd /Users/xiexiyang/Documents/mybloglivereload 在浏览器中激活chrome插件 效果图： 如何在文中中插入 gif 动图推荐使用 licecap。 我上面的 livereload 动图就是使用的licecap录制的。","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"自建博客","slug":"自建博客","permalink":"http://yoursite.com/tags/自建博客/"}]},{"title":"spring 实现动态数据源配置","slug":"spring-实现动态数据源配置","date":"2017-09-14T16:00:00.000Z","updated":"2017-09-21T03:33:16.000Z","comments":true,"path":"2017/09/15/spring-实现动态数据源配置/","link":"","permalink":"http://yoursite.com2017/09/15/spring-实现动态数据源配置/","excerpt":"","text":"背景 1、当项目慢慢变大，访问量也慢慢变大的时候，就难免的要使用多个数据源和设置读写分离了。 2、如果你做的是一个数据报表或文件导出的系统，需要处理的数据可能是来源于多个数据库，如何在应用中动态的支持多个数据源的添加和删除？可以做到在不重启应用服务器的同时动态的添加和删除数据源吗？ 我们分为两个步骤来思考如上的两个问题，首先解决读写分离的问题，再来解决动态多数据源的问题。 见过比较多的读写分离处理方式，主要分为两步： 1、对于开发人员，要求serivce类的方法名必须遵守规范，读操作以query、get等开头，写操作以update、delete开头。2、配置一个拦截器，依据方法名判断是读操作还是写操作，设置相应的数据源。 以上做法能实现最简单的读写分离，但相应的也会有很多不方便的地方： 1、数据源的管理不太方便，基本上只有2个数据源了，一个读一个写。这个可以在spring中声明多个bean来解决该问题，但bean的id和数据源的功能也就绑定了。 2、因为读写分离往往是在项目慢慢变大后加入的，不是一开始就有，上面说到的第二点方法名可能会各式各样，find、insert、save、exe等等，这些都要一一修改，且要保证以后读的方法名中不能有写操作。也可以拦截的底层一点如JdbcTemplate，但这样会导致交叉设置数据源。 3、数据源无法动态修改，只能在项目启动时加载。 以上问题我想开发人员多多少少都会遇到，这也是本文要讨论的问题。 本文使用到的技术栈有： spring druid（alibaba 提供的一个数据库连接池） mybatis 单数据源的配置如下是一个项目中常用的单数据源的配置方式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;?useUnicode=true&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;allowMultiQueries=true&amp;amp;autoReconnect=true\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=\"initialSize\" value=\"1\" /&gt; &lt;property name=\"minIdle\" value=\"1\" /&gt; &lt;property name=\"maxActive\" value=\"20\" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=\"maxWait\" value=\"60000\" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=\"timeBetweenEvictionRunsMillis\" value=\"60000\" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=\"minEvictableIdleTimeMillis\" value=\"300000\" /&gt; &lt;property name=\"validationQuery\" value=\"SELECT 'x'\" /&gt; &lt;property name=\"testWhileIdle\" value=\"true\" /&gt; &lt;property name=\"testOnBorrow\" value=\"false\" /&gt; &lt;property name=\"testOnReturn\" value=\"false\" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\" /&gt; &lt;property name=\"maxPoolPreparedStatementPerConnectionSize\" value=\"20\" /&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name=\"filters\" value=\"stat,log4j\" /&gt; &lt;/bean&gt; &lt;bean id=\"log-filter\" class=\"com.alibaba.druid.filter.logging.Log4jFilter\"&gt; &lt;property name=\"statementExecutableSqlLogEnable\" value=\"true\" /&gt;&lt;/bean&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!--dataSource属性指定要用到的连接池--&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!--configLocation属性指定mybatis的核心配置文件--&gt; &lt;property name=\"configLocation\" value=\"classpath:sqlMapConfig.xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"sqlSessionFactory\" /&gt;&lt;/bean&gt;&lt;bean id=\"txManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt;&lt;/bean&gt; 多数据源的配置如下是一个多数据源的配置方式，可以支持读写分离，针对于不同的dao，配置不同的sqlSessionFactory即可实现从不同的数据源获取和操作数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;?useUnicode=true&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;allowMultiQueries=true&amp;amp;autoReconnect=true\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt;&lt;/bean&gt;&lt;bean id=\"log-filter\" class=\"com.alibaba.druid.filter.logging.Log4jFilter\"&gt; &lt;property name=\"statementExecutableSqlLogEnable\" value=\"true\" /&gt;&lt;/bean&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!--dataSource属性指定要用到的连接池--&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!--configLocation属性指定mybatis的核心配置文件--&gt; &lt;property name=\"configLocation\" value=\"classpath:sqlMapConfig.xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"sqlSessionFactory\" /&gt;&lt;/bean&gt;&lt;bean id=\"readDataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.readonly.url&#125;?useUnicode=true&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;allowMultiQueries=true&amp;amp;autoReconnect=true\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.readonly.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.readonly.password&#125;\" /&gt;&lt;/bean&gt;&lt;bean id=\"readSqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!--dataSource属性指定要用到的连接池--&gt; &lt;property name=\"dataSource\" ref=\"readDataSource\"/&gt; &lt;!--configLocation属性指定mybatis的核心配置文件--&gt; &lt;property name=\"configLocation\" value=\"classpath:sqlMapConfig.xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"readSqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"readSqlSessionFactory\" /&gt;&lt;/bean&gt;&lt;bean id=\"pdfPasswordDao\" class=\"org.mybatis.spring.mapper.MapperFactoryBean\"&gt; &lt;property name=\"mapperInterface\" value=\"com.qding.dcenter.dao.IPdfPasswordDao\"/&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\"/&gt;&lt;/bean&gt;&lt;bean id=\"summaryReportDaoReadOnly\" class=\"org.mybatis.spring.mapper.MapperFactoryBean\"&gt; &lt;property name=\"mapperInterface\" value=\"com.qding.dcenter.dao.ISummaryReportDao\"/&gt; &lt;property name=\"sqlSessionFactory\" ref=\"readSqlSessionFactory\"/&gt;&lt;/bean&gt; 动态多数据源这里的动态指的是什么呢？ 在我看来一个好的动态数据源，应该跟单数据源一样让使用者感觉不到他是动态的，至少dao层的开发者应该感觉不到。先来看张图： 基于spring实现动态数据源其实spring早就想到了这一点，也已经为我们准备好了扩展类AbstractRoutingDataSource，我们只需要一个简单的实现即可。网上关于这个类文章很多，但都比较粗浅没有讲到点子上，只是实现了多个数据源而已。 这里我们同样来实现AbstractRoutingDataSource，它只要求实现一个方法：12345678/** * Determine the current lookup key. This will typically be * implemented to check a thread-bound transaction context. * &lt;p&gt;Allows for arbitrary keys. The returned key needs * to match the stored lookup key type, as resolved by the * &#123;@link #resolveSpecifiedLookupKey&#125; method. */protected abstract Object determineCurrentLookupKey(); 你可以简单的理解它：spring把所有的数据源都存放在了一个map中，这个方法返回一个key告诉spring用这个key从map中去取。 AbstractRoutingDataSource 实现了 InitializingBean 那么spring在初始化该bean时，会调用InitializingBean的接口void afterPropertiesSet() throws Exception; 我们看下AbstractRoutingDataSource是如何实现这个接口的：123456789101112131415@Overridepublic void afterPropertiesSet() &#123; if (this.targetDataSources == null) &#123; throw new IllegalArgumentException(\"Property 'targetDataSources' is required\"); &#125; this.resolvedDataSources = new HashMap&lt;Object, DataSource&gt;(this.targetDataSources.size()); for (Map.Entry&lt;Object, Object&gt; entry : this.targetDataSources.entrySet()) &#123; Object lookupKey = resolveSpecifiedLookupKey(entry.getKey()); DataSource dataSource = resolveSpecifiedDataSource(entry.getValue()); this.resolvedDataSources.put(lookupKey, dataSource); &#125; if (this.defaultTargetDataSource != null) &#123; this.resolvedDefaultDataSource = resolveSpecifiedDataSource(this.defaultTargetDataSource); &#125;&#125; targetDataSources 是我们在xml配置文件中注入的 dataSourceMaster 和 dataSourceSlave. afterPropertiesSet方法就是使用注入的dataSourceMaster 和 dataSourceSlave来构造一个HashMap——resolvedDataSources。方便后面根据 key 从该map 中取得对应的dataSource。我们在看下 AbstractDataSource 接口中的 Connection getConnection() throws SQLException; 是如何实现的：1234@Overridepublic Connection getConnection() throws SQLException &#123; return determineTargetDataSource().getConnection();&#125; 关键在于 determineTargetDataSource()，根据方法名就可以看出，应该此处就决定了使用哪个 dataSource ：123456789101112protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, \"DataSource router not initialized\"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException(\"Cannot determine target DataSource for lookup key [\" + lookupKey + \"]\"); &#125; return dataSource;&#125; Object lookupKey = determineCurrentLookupKey(); 该方法是我们实现的，在其中获取ThreadLocal中保存的 key 值。获得了key之后，在从afterPropertiesSet()中初始化好了的resolvedDataSources这个map中获得key对应的dataSource。而ThreadLocal中保存的 key 值是通过AOP的方式在调用service中相关方法之前设置好的。OK，到此搞定！ 它还有个targetDataSources和defaultTargetDataSource属性，网上的一堆做法是继承这个类，然后在声明bean的时候注入dataSource：12345678910&lt;bean id=\"dynamicdatasource\" class=\"......\"&gt; &lt;property name=\"targetDataSources\"&gt; &lt;map&gt; &lt;entry key=\"dataSource1\" value-ref=\"dataSource1\" /&gt; &lt;entry key=\"dataSource2\" value-ref=\"dataSource2\" /&gt; &lt;entry key=\"dataSource3\" value-ref=\"dataSource3\" /&gt; &lt;/map&gt; &lt;/property&gt; &lt;property name=\"defaultTargetDataSource\" ref=\"dataSource1\" /&gt;&lt;/bean&gt; 这样虽然简单，但是弊端也是显而易见的，除了使用了多个数据源之外没有我们想要的任何操作。但是如果不配置targetDataSources，spring在启动的时候就会抛出异常而无法运行。 一种动态数据源配置1) 先定义一个enum来表示不同的数据源：12345678package net.aazj.enums;/** * 数据源的类别：master/slave */public enum DataSources &#123; MASTER, SLAVE&#125; 2）通过 TheadLocal 来保存每个线程选择哪个数据源的标志(key)： 123456789101112131415161718192021222324package net.aazj.util;import net.aazj.enums.DataSources;public class DataSourceTypeManager &#123; private static final ThreadLocal&lt;DataSources&gt; dataSourceTypes = new ThreadLocal&lt;DataSources&gt;()&#123; @Override protected DataSources initialValue()&#123; return DataSources.MASTER; &#125; &#125;; public static DataSources get()&#123; return dataSourceTypes.get(); &#125; public static void set(DataSources dataSourceType)&#123; dataSourceTypes.set(dataSourceType); &#125; public static void reset()&#123; dataSourceTypes.set(DataSources.MASTER0); &#125;&#125; 3）定义 ThreadLocalRountingDataSource，继承AbstractRoutingDataSource： 12345678910package net.aazj.util;import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;public class ThreadLocalRountingDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DataSourceTypeManager.get(); &#125;&#125; 4）在配置文件中向 ThreadLocalRountingDataSource 注入 master 和 slave 的数据源： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;!-- 配置数据源Master --&gt;&lt;bean name=\"dataSourceMaster\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;property name=\"url\" value=\"$&#123;jdbc_url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc_username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc_password&#125;\" /&gt; &lt;!-- 初始化连接大小 --&gt; &lt;property name=\"initialSize\" value=\"0\" /&gt; &lt;!-- 连接池最大使用连接数量 --&gt; &lt;property name=\"maxActive\" value=\"20\" /&gt; &lt;!-- 连接池最大空闲 --&gt; &lt;property name=\"maxIdle\" value=\"20\" /&gt; &lt;!-- 连接池最小空闲 --&gt; &lt;property name=\"minIdle\" value=\"0\" /&gt; &lt;!-- 获取连接最大等待时间 --&gt; &lt;property name=\"maxWait\" value=\"60000\" /&gt;&lt;/bean&gt; &lt;!-- 配置数据源Slave --&gt;&lt;bean name=\"dataSourceSlave\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;property name=\"url\" value=\"$&#123;jdbc_url_slave&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc_username_slave&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc_password_slave&#125;\" /&gt; &lt;!-- 初始化连接大小 --&gt; &lt;property name=\"initialSize\" value=\"0\" /&gt; &lt;!-- 连接池最大使用连接数量 --&gt; &lt;property name=\"maxActive\" value=\"20\" /&gt; &lt;!-- 连接池最大空闲 --&gt; &lt;property name=\"maxIdle\" value=\"20\" /&gt; &lt;!-- 连接池最小空闲 --&gt; &lt;property name=\"minIdle\" value=\"0\" /&gt; &lt;!-- 获取连接最大等待时间 --&gt; &lt;property name=\"maxWait\" value=\"60000\" /&gt;&lt;/bean&gt; &lt;bean id=\"dataSource\" class=\"net.aazj.util.ThreadLocalRountingDataSource\"&gt; &lt;property name=\"defaultTargetDataSource\" ref=\"dataSourceMaster\" /&gt; &lt;property name=\"targetDataSources\"&gt; &lt;map key-type=\"net.aazj.enums.DataSources\"&gt; &lt;entry key=\"MASTER\" value-ref=\"dataSourceMaster\"/&gt; &lt;entry key=\"SLAVE\" value-ref=\"dataSourceSlave\"/&gt; &lt;!-- 这里还可以加多个dataSource --&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;property name=\"configLocation\" value=\"classpath:config/mybatis-config.xml\" /&gt; &lt;property name=\"mapperLocations\" value=\"classpath*:config/mappers/**/*.xml\" /&gt;&lt;/bean&gt; &lt;!-- Transaction manager for a single JDBC DataSource --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt;&lt;/bean&gt; &lt;!-- 使用annotation定义事务 --&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\" /&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"net.aazj.mapper\" /&gt; &lt;!-- &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; --&gt;&lt;/bean&gt; 上面spring的配置文件中，我们针对master数据库和slave数据库分别定义了dataSourceMaster和dataSourceSlave两个dataSource，然后注入到 中，这样我们的dataSource就可以来根据 key 的不同来选择dataSourceMaster和 dataSourceSlave了。 5）使用Spring AOP 来指定 dataSource 的 key ，从而dataSource会根据key选择 dataSourceMaster 和 dataSourceSlave： 123456789101112131415161718192021222324package net.aazj.aop;import net.aazj.enums.DataSources;import net.aazj.util.DataSourceTypeManager;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;@Aspect // for aop@Component // for auto scan@Order(0) // execute before @Transactionalpublic class DataSourceInterceptor &#123; @Pointcut(\"execution(public * net.aazj.service..*.getUser(..))\") public void dataSourceSlave()&#123;&#125;; @Before(\"dataSourceSlave()\") public void before(JoinPoint jp) &#123; DataSourceTypeManager.set(DataSources.SLAVE); &#125; // ... ...&#125; 这里我们定义了一个 Aspect 类，我们使用 @Before 来在符合 @Pointcut(“execution(public net.aazj.service...getUser(..))”) 中的方法被调用之前，调用 DataSourceTypeManager.set(DataSources.SLAVE) 设置了 key 的类型为 DataSources.SLAVE，所以 dataSource 会根据key=DataSources.SLAVE 选择 dataSourceSlave 这个dataSource。所以该方法对于的sql语句会在slave数据库上执行(经网友老刘1987提醒，这里存在多个Aspect之间的一个执行顺序的问题，必须保证切换数据源的Aspect必须在@Transactional这个Aspect之前执行，所以这里使用了@Order(0)来保证切换数据源先于@Transactional执行)。 我们可以不断的扩充 DataSourceInterceptor 这个 Aspect，在中进行各种各样的定义，来为某个service的某个方法指定合适的数据源对应的dataSource。 这样我们就可以使用 Spring AOP 的强大功能来，十分灵活进行配置了。 可以动态添加、修改的动态数据源实现上面的依然有如下的问题 数据源的管理不太方便，基本上只有2个数据源了，一个读一个写。这个可以在spring中声明多个bean来解决该问题，但bean的id和数据源的功能也就绑定了。 因为读写分离往往是在项目慢慢变大后加入的，不是一开始就有，上面说到的第二点方法名可能会各式各样，find、insert、save、exe等等，这些都要一一修改，且要保证以后读的方法名中不能有写操作。也可以拦截的底层一点如JdbcTemplate，但这样会导致交叉设置数据源。 数据源无法动态修改，只能在项目启动时加载。 怎么样实现数据源的动态添加和修改呢，即使项目启动了也可以在不重启服务的时候实现修改和变动 写一个DynamicDataSourceManager 实现InitializingBean接口，继承AbstractRoutingDataSource123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class DynamicDataSourceManager extends AbstractRoutingDataSource implements InitializingBean &#123; private Map&lt;Object,Object&gt; dsMap = new ConcurrentHashMap&lt;&gt;(); @Resource(name=\"exportDatasourceDao\") private IExportDatasourceDao exportDatasourceDao; /** * 根据配置动态添加或更新一个数据源 * @param connConfig 数据源配置 */ public void addDataSource(ExportDatasource connConfig) &#123; logger.info(\"[addDataSource] config=\"+ JSON.toJSONString(connConfig)); DruidDataSource ds = createDatasource(connConfig); dsMap.put(connConfig.getName(),ds); this.setTargetDataSources(dsMap); super.afterPropertiesSet(); &#125; /** * 初始化所有的数据源 */ private void initDataSources() &#123; logger.info(\"[initDataSources] start.\"); List&lt;ExportDatasource&gt; dsList = exportDatasourceDao.findAll(); for(ExportDatasource connConfig : dsList)&#123; DruidDataSource ds = createDatasource(connConfig); dsMap.put(connConfig.getName(),ds); &#125; this.setTargetDataSources(dsMap); super.afterPropertiesSet(); logger.info(\"[initDataSources] end, datasource size = \"+dsList.size()); &#125; @Override protected Object determineCurrentLookupKey() &#123; logger.info(\"determineCurrentLookupKey key=\"+DynamicDataSourceHolder.getDataSource()); return DynamicDataSourceHolder.getDataSource(); &#125; @Override public void afterPropertiesSet() &#123; this.initDataSources(); &#125; /** * 初始化一个数据源 * @param connConfig */ private DruidDataSource createDatasource(ExportDatasource connConfig)&#123; DruidDataSource ds = new DruidDataSource(); //连接属性 //jdbc:mysql://10.37.253.42:3307/qding_shield //jdbc:hive2://10.37.5.116:21051/qding_api_log/;auth=noSasl String url = \"\"; if(DB_TYPE_MYSQL.equals(connConfig.getType()))&#123; url = String.format(\"jdbc:mysql://%s:%d?useUnicode=true&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;allowMultiQueries=true&amp;amp;autoReconnect=true\",connConfig.getIp(),connConfig.getPort()); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); &#125;else if(DB_TYPE_IMPALA.equals(connConfig.getType()))&#123; url = String.format(\"jdbc:hive2://%s:%d/;auth=noSasl\",connConfig.getIp(),connConfig.getPort()); ds.setDriverClassName(\"org.apache.hive.jdbc.HiveDriver\"); &#125; ds.setUrl(url); ds.setUsername(connConfig.getUserName()); if(connConfig.getPassword()!=null) &#123; ds.setPassword(connConfig.getPassword()); &#125; //其它参数属性 ds.setInitialSize(initialSize); ds.setMinIdle(minIdle); ds.setMaxActive(maxActive); //配置获取连接等待超时的时间 ds.setMaxWait(maxWait); //配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 ds.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); //配置一个连接在池中最小生存的时间，单位是毫秒 ds.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); //打开PSCache，并且指定每个连接上PSCache的大小 ds.setPoolPreparedStatements(poolPreparedStatements); ds.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); ds.setName(connConfig.getName()); return ds; &#125;&#125; 我们实现一个初始化数据源的方法initDataSources在本方法中完成数据源的初始化，并调用父类的this.setTargetDataSources(dsMap);那么什么时候来运行这个解析的方法呢？有些同学可能一下就想到了spring声明bean时的init-method属性，但是这里不行。因为init-method是在bean初始化完成之后调用的，当spring在初始化DynamicDataSource时发现这两个属性是空的异常就抛出来了，根本就没有机会去运行init-method。 所以我们要在bean的初始化过程中来解析并存入我们的数据源。要实现这个操作，我们可以实现spring的InitializingBean接口。由于AbstractRoutingDataSource已经实现了该接口，我们只需要重写该方法就行。也就是说DynamicDataSource要实现以下两个方法：12345678@Overrideprotected Object determineCurrentLookupKey() &#123; ...&#125;@Overridepublic void afterPropertiesSet() &#123; this.initDataSources();&#125; 在afterPropertiesSet方法中实现我们解析数据源的操作。但是这样还不够，因为spring容器并不知道你做了这些，所以最后的一行super.afterPropertiesSet();千万别忘了，用来通知spring容器。 到这里数据源的解析已经完成了，我们又怎么样来取数据源呢？ 这个我们可以利用ThreadLocal来实现。编写DynamicDataSourceHolder类 123456789101112131415161718192021package com.qding.knight.datasource;/** * Created by xiexiyang on 2017/7/12. */public class DynamicDataSourceHolder &#123; //线程本地环境 private static final ThreadLocal&lt;String&gt; dataSources = new ThreadLocal&lt;String&gt;(); //设置数据源 public static void setDataSource(String customerType) &#123; dataSources.set(customerType); &#125; //获取数据源 public static String getDataSource() &#123; return (String) dataSources.get(); &#125; //清除数据源 public static void clearDataSource() &#123; dataSources.remove(); &#125;&#125; 配置如下：1234567891011121314&lt;bean id=\"dynamicDataSource\" class=\"com.qding.knight.datasource.DynamicDataSourceManager\"&gt;&lt;/bean&gt;&lt;bean id=\"exportSqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!--dataSource属性指定要用到的连接池--&gt; &lt;property name=\"dataSource\" ref=\"dynamicDataSource\"/&gt; &lt;!--configLocation属性指定mybatis的核心配置文件--&gt; &lt;property name=\"configLocation\" value=\"classpath:exportSqlMapConfig.xml\"/&gt;&lt;/bean&gt;&lt;!-- 通过扫描的模式，扫描目录在com/hoo/mapper目录下，所有的mapper都继承SqlMapper接口的接口 --&gt;&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.qding.knight.dao2\" /&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"exportSqlSessionFactory\"/&gt;&lt;/bean&gt; 使用方式如下： 参考资料Spring, MyBatis 多数据源的配置和管理http://www.cnblogs.com/digdeep/p/4512368.html Spring实现动态数据源，支持动态添加、删除和设置权重及读写分离https://www.dexcoder.com/selfly/article/4048","categories":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/categories/spring/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"动态数据源","slug":"动态数据源","permalink":"http://yoursite.com/tags/动态数据源/"}]},{"title":"浅论软件开发的本质","slug":"浅论软件开发的本质","date":"2017-09-14T16:00:00.000Z","updated":"2017-09-21T02:31:11.000Z","comments":true,"path":"2017/09/15/浅论软件开发的本质/","link":"","permalink":"http://yoursite.com2017/09/15/浅论软件开发的本质/","excerpt":"","text":"从毕业到现在6年了，带上大学的4年，加起来进入这个行业也有了10年了，十年就这么不快不慢的过去了。接触的行业有出版社的资源管理系统、在线学习系统、大数据数据挖掘和电商交易系统。挖过一些坑，也踩过很多雷，回头梳理下开发过和接触过的系统，希望从个人的理解角度探究下软件系统的本质是什么？ 我个人认为在软件开发领域几个核心的概念是：数据存储、数据获取传输和数据展示。每一个软件都承担了其中的一个或几个角色。我们软件开发人员要做的事情也是把数据获取出来展示给需要的人看。 为何是这样说呢？ 看上面的图，可以套用到大多数的互联网或非互联网软件产品中去。我们每个人每天都在生产大量的数据，也会消费大量的数据。比如视频、图片或文字这些都是数据的一种。 作为软件开发者，我们要做的就是把互联网上用户的数据收集并保存下来，把用户需要的数据拿到并展示给用户。 比如我现在在写的这个文件，假如我使用Sublime来编写，Sublime就是一个软件，这个文章的源文件保存到本地磁盘上，本地磁盘就是一个存储介质，Sublime打开文件便是数据的展示。假如我把源文件上传到github，打开浏览器依然可以看到文件的内容，此时数据便存储到了github远程的服务器上，展示的载体便变为了浏览器。 日常的软件开发也是如此，我们接到一个需求，进入开发之前首先要考虑的便是数据模型的抽象和设计，我们需要保存哪些数据，数据会存放到什么地方，应该给用户如何展示，展示的形式是什么样子的。 对应到具体的开发，比如我们要做一个会员系统，提供会员注册、登录和管理等功能，作为一个java web的开发人员，使用的技术栈有： spring MVC/spring 负责web业务处理 mybatis/druid 负责mysql数据的获取 mysql 存储用户基础信息 七牛 存储用户头像 html/js/angularjs 前端展示 对于普通的用户来讲，注册只需要在浏览器填写用户名，密码，点击提交即可，数据会在服务器端做验证，并保存到数据库。用户登录的时候，从数据库获取数据做匹配，完成登录的动作。 每一个业务流程都是类似的框架结构，数据在不同的端做流转，转化。开发人员的核心价值便是管理这些数据，正确的收集，正确的存储，正确的获取以及有效的展示。","categories":[{"name":"方法论","slug":"方法论","permalink":"http://yoursite.com/categories/方法论/"}],"tags":[{"name":"软件开发","slug":"软件开发","permalink":"http://yoursite.com/tags/软件开发/"}]},{"title":"ArrayList 和 Vector 的区别","slug":"05-java集合类之-ArrayList-和-Vector-的区别","date":"2017-09-12T04:08:58.000Z","updated":"2017-09-14T08:31:41.000Z","comments":true,"path":"2017/09/12/05-java集合类之-ArrayList-和-Vector-的区别/","link":"","permalink":"http://yoursite.com2017/09/12/05-java集合类之-ArrayList-和-Vector-的区别/","excerpt":"","text":"1. Synchronization and Thread-SafeVector is synchronized while ArrayList is not synchronized . Synchronization and thread safe means at a time only one thread can access the code .In Vector class all the methods are synchronized .Thats why the Vector object is already synchronized when it is created . 2. PerformanceVector is slow as it is thread safe . In comparison ArrayList is fast as it is non synchronized . Thus in ArrayList two or more threads can access the code at the same time , while Vector is limited to one thread at a time. 3. Automatic Increase in CapacityA Vector defaults to doubling size of its array . While when you insert an element into the ArrayList , it increasesits Array size by 50% . By default ArrayList size is 10 . It checks whether it reaches the last element then it will create the new array ,copy the new data of last array to new array ,then old array is garbage collected by the Java Virtual Machine (JVM) . 4. Set Increment SizeArrayList does not define the increment size . Vector defines the increment size . You can find the following method in Vector Class public synchronized void setSize(int i) { //some code } There is no setSize() method or any other method in ArrayList which can manually set the increment size. 5. EnumeratorOther than Hashtable ,Vector is the only other class which uses both Enumeration and Iterator .While ArrayList can only use Iterator for traversing an ArrayList . 6. Introduction in Javajava.util.Vector class was there in java since the very first version of the java development kit (jdk).java.util.ArrayList was introduced in java version 1.2 , as part of Java Collections framework . In java version 1.2 , Vector class has been refactored to implement the List Inteface .","categories":[{"name":"java 集合","slug":"java-集合","permalink":"http://yoursite.com/categories/java-集合/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"LinkedList 详解和源码解析","slug":"03-java集合类之LinkedList","date":"2017-09-12T02:54:35.000Z","updated":"2017-09-14T08:31:57.000Z","comments":true,"path":"2017/09/12/03-java集合类之LinkedList/","link":"","permalink":"http://yoursite.com2017/09/12/03-java集合类之LinkedList/","excerpt":"","text":"LinkedList简介 LinkedList 是一个继承于AbstractSequentialList的双向链表。它也可以被当作堆栈、队列或双端队列进行操作。 LinkedList 实现 List 接口，能对它进行队列操作。 LinkedList 实现 Deque 接口，即能将LinkedList当作双端队列使用。 LinkedList 实现了Cloneable接口，即覆盖了函数clone()，能克隆。 LinkedList 实现java.io.Serializable接口，这意味着LinkedList支持序列化，能通过序列化去传输。 LinkedList 是非同步的。 类声明123public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 类继承关系图 构造函数1234567public LinkedList() &#123;&#125;public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 数据结构123456789101112131415161718192021222324transient int size = 0;/** * Pointer to first node. */transient Node&lt;E&gt; first;/** * Pointer to last node. */transient Node&lt;E&gt; last;private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 重要方法实现add12345678910111213141516171819public boolean add(E e) &#123; linkLast(e); return true;&#125;/** * Links e as last element. */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; 新加入的元素会变为最后一个元素，如果是第一次添加，也就是last==null，则first==last==newNode get1234567891011121314151617181920public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; //检查index是否小于集合大小的半，来决定是从头查找还是从尾部查找 Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 在LinkedList中获取指定位置的一个元素需要挨个遍历，jdk做了简单的一个优化，首先判断index是否小于集合大小的半，来决定是从头查找还是从尾部查找，这样可以减少遍历的次数。 队列的操作12345678910//获取一个元素，不删除public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125;//从头获取一个元素，同时删除此元素public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);&#125;","categories":[{"name":"java 集合","slug":"java-集合","permalink":"http://yoursite.com/categories/java-集合/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"ArrayList 详解和源码解析","slug":"03-java集合类之ArrayList","date":"2017-09-11T09:33:37.000Z","updated":"2017-09-14T08:32:00.000Z","comments":true,"path":"2017/09/11/03-java集合类之ArrayList/","link":"","permalink":"http://yoursite.com2017/09/11/03-java集合类之ArrayList/","excerpt":"","text":"概述ArrayList 是一个数组队列，相当于 动态数组。与Java中的数组相比，它的容量能动态增长。它继承于AbstractList，实现了List, RandomAccess, Cloneable, java.io.Serializable这些接口。 ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。ArrayList 实现了RandmoAccess接口，即提供了随机访问功能。RandmoAccess是java中用来被List实现，为List提供快速访问功能的。在ArrayList中，我们即可以通过元素的序号快速获取元素对象；这就是快速随机访问。稍后，我们会比较List的“快速随机访问”和“通过Iterator迭代器访问”的效率。 ArrayList 实现了Cloneable接口，即覆盖了函数clone()，能被克隆。 ArrayList 实现java.io.Serializable接口，这意味着ArrayList支持序列化，能通过序列化去传输。 和Vector不同，ArrayList中的操作不是线程安全的！所以，建议在单线程中才使用ArrayList，而在多线程中可以选择Vector或者CopyOnWriteArrayList。 ArrayList 构造函数12345678// 默认构造函数ArrayList()// capacity是ArrayList的默认容量大小。当由于增加数据导致容量不足时，容量会添加上一次容量大小的一半。ArrayList(int capacity)// 创建一个包含collection的ArrayListArrayList(Collection&lt;? extends E&gt; collection) ArrayList 类图结构如下 源码解析ArrayList 中有两个重要的变量 private transient Object[] elementData; elementData 是一个Object的数组，JDK 实现了一个动态数组，可以动态的增加数组的大小，初始的大小是10。 private int size; size 标示了动态数组的实际大小 构造函数：1234567891011121314151617181920212223242526272829/** * 创建一个指定容量大小的空数组 */public ArrayList(int initialCapacity) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); this.elementData = new Object[initialCapacity];&#125;/** * 创建一个空数组 */public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA;&#125;/** * 创建一个包含传递进来的元素的数组 */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); size = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class);&#125; add方法的实现 12345678910111213141516171819202122232425262728293031323334353637383940414243// 添加一个元素public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;// 确定容量private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; ArrayList 默认的构造函数，创建的是一个空数组，是在第一次添加对象的时候做的初始化。 添加元素的时候如果容量不足，会进行扩容，新的容量会之前的1.5倍 最大的容量为 Integer.MAX_VALUE 遍历的三种方式ArrayList支持3种遍历方式 (01) 第一种，通过迭代器遍历。即通过Iterator去遍历。 12345Integer value = null;Iterator iter = list.iterator();while (iter.hasNext()) &#123; value = (Integer)iter.next();&#125; (02) 第二种，随机访问，通过索引值去遍历。由于ArrayList实现了RandomAccess接口，它支持通过索引值去随机访问元素。 12345Integer value = null;int size = list.size();for (int i=0; i&lt;size; i++) &#123; value = (Integer)list.get(i); &#125; (03) 第三种，for循环遍历。如下： 1234Integer value = null;for (Integer integ:list) &#123; value = integ;&#125; ConcurrentModificationExceptionAbstractList 中有一个成员变量 modCount, 记录了数据在结构上变化的次数，比如添加或删除一个元素的次数12// The number of times this list has been structurally modifiedprotected transient int modCount = 0; 在Java中的fail-fast机制中有介绍过。在使用迭代器遍历元素的时候，在对集合进行删除的时候一定要注意，使用不当有可能发生ConcurrentModificationException。","categories":[{"name":"java 集合","slug":"java-集合","permalink":"http://yoursite.com/categories/java-集合/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"Java Collection 架构","slug":"02-java集合类之Collection-架构","date":"2017-09-07T09:52:03.000Z","updated":"2017-09-14T08:57:04.000Z","comments":true,"path":"2017/09/07/02-java集合类之Collection-架构/","link":"","permalink":"http://yoursite.com2017/09/07/02-java集合类之Collection-架构/","excerpt":"","text":"概要首先看一下 Collection 的类图结构如下： Collection 是一个接口，它主要有两个分支 List 和 Set。 List 和 Set 是两个接口，他们继承自 Collection ，List 是有序的队列，元素可以重复， Set 是不重复的的集合。 为了减少重复代码，jdk 抽象出了一个 AbstractCollection 抽象类，这个类实现了 Collection 中绝大部分函数，这样在其它的实现类中就可以省去重复的编码。 AbstractList 和 AbstractSet都继承于AbstractCollection，具体的List实现类继承于AbstractList，而Set的实现类则继承于AbstractSet。 Collection 类详解Collection 的定义如下：1public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; &#123; 包含的方法如下： List 详解接口声明： 1public interface List&lt;E&gt; extends Collection&lt;E&gt; &#123; 包含的方法： ![](image:: http://7xo9p3.com1.z0.glb.clouddn.com/markdown/1505118343539.png?imageMogr2/thumbnail/!100p/quality/100!） 其中带 上箭头 是从 Collection 继承来的，相比于 Collection ，主要增加了一些在指定位置添加、删除、修改、获取对应元素的接口。还有获取List中的子队列。 Set 详解接口声明 1public interface Set&lt;E&gt; extends Collection&lt;E&gt; &#123; 包含的方法： 关于API方面。Set的API和Collection完全一样。","categories":[{"name":"java 集合","slug":"java-集合","permalink":"http://yoursite.com/categories/java-集合/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"一些好玩的前端项目","slug":"一些好玩的前端项目","date":"2017-07-12T16:00:00.000Z","updated":"2017-09-15T02:44:01.000Z","comments":true,"path":"2017/07/13/一些好玩的前端项目/","link":"","permalink":"http://yoursite.com2017/07/13/一些好玩的前端项目/","excerpt":"","text":"web 代码编辑器https://ace.c9.io/#nav=howto&amp;api=editor Features Syntax highlighting for over 110 languages (TextMate/Sublime Text.tmlanguage files can be imported) Over 20 themes (TextMate/Sublime Text .tmtheme files can be imported) Automatic indent and outdent An optional command line Handles huge documents (four million lines seems to be the limit!) Fully customizable key bindings including vim and Emacs modes Search and replace with regular expressions Highlight matching parentheses Toggle between soft tabs and real tabs Displays hidden characters Drag and drop text using the mouse Line wrapping Code folding Multiple cursors and selections Live syntax checker (currently JavaScript/CoffeeScript/CSS/XQuery) Cut, copy, and paste functionality web diff工具http://www.mergely.com/doc Mergely is a powerful online diff and merge editor and javascript library that highlights changes in text. It can be embedded within your own Web application to compare files, text, C, C++, Java, HTML, XML, CSS, and javascript. Download Mergely, and refer to the reference manual. Please refer to the the license agreement. Browser-based differencing tool Diff or Merge changes in your own web applications Always available Free and GPLv3 Commercial license available Share diffs online for demonstration or discussion Simple to use Mergely is written with the aid of Code Mirror and jQuery javascript libraries, and uses HTML5 canvas to markup the differences between documents. It will work in most modern browsers. 代码高亮http://codemirror.net/ CodeMirror is a versatile text editor implemented in JavaScript for the browser. It is specialized for editing code, and comes with a number of language modes and addons that implement more advanced editing functionality. Features Support for over 100 languages out of the box A powerful, composable language mode system Autocompletion (XML) Code folding Configurable keybindings Vim, Emacs, and Sublime Text bindings Search and replace interface Bracket and tag matching Support for split views Linter integration Mixing font sizes and styles Various themes Able to resize to fit content Inline and block widgets Programmable gutters Making ranges of text styled, read-only, or atomic Bi-directional text support Many other methods and addons… pdfjshttps://github.com/mozilla/pdf.js/ PDF.js is a Portable Document Format (PDF) viewer that is built with HTML5. PDF.js is community-driven and supported by Mozilla Labs. Our goal is to create a general-purpose, web standards-based platform for parsing and rendering PDFs. JSON Server &amp;&amp; faker.jshttps://github.com/typicode/json-server Get a full fake REST API with zero coding in less than 30 seconds (seriously) https://github.com/marak/Faker.js/ generate massive amounts of fake data in Node.js and the browser 介绍两大神器！——使用json-server和faker.js模拟REST APIhttps://segmentfault.com/a/1190000008574028","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"}]},{"title":"python 学习笔记","slug":"2013-09-26-python","date":"2017-07-06T08:02:32.000Z","updated":"2017-09-21T01:55:42.000Z","comments":true,"path":"2017/07/06/2013-09-26-python/","link":"","permalink":"http://yoursite.com2017/07/06/2013-09-26-python/","excerpt":"","text":"字符串、文件、目录、列表和网络的一些笔记 字符串相关实现字符串对齐123实现字符串对齐：左对齐、右对齐和居中对齐ljust、rjust、center，可以是一个或两个参数，第二个参数指定占位符&apos;aaa&apos;.ljust(20)或&apos;aaa&apos;.ljust(20,&apos;=&apos;) 去掉字符串两端的空格1使用lstrip、rstrip、和strip方法 格式字符串12可以使用%s来格式化字符串，把存储在变量中的字符串片段连接起来s = &apos;%s%s something %s yet more&apos; % (a,b,c) 不要使用+或+=来拼接大的字符串，通常会造成性能问题12可以使用一个list作为中间数据结构来容纳他们，使用list的append或extend方法在末尾添加新的数据。在取得所有的数据之后再调用&apos;&apos;.join(thelist)就可以得到合并之后的大字符串。 反转字符串 按字符反转 12a = 'hello'revchars = a[::-1] 按单词反转 12345可以先创建一个单词的列表，然后将列表反转，再用join方法将其合并list = str.split()revwords = &apos; &apos;.join(list.reverse())或revwords = &apos; &apos;.join(str.split()[::-1]) 分割字符串(split)1234&gt;&gt;&gt; '1+2+3+4+5'.split('+')['1','2','3','4','5']如果不加参数，默认使用空格，包括空格、制表、换行等 列表定义：列表是Python中使用最频繁的数据类型【可以说没有之一】 关键词：有序，可变12345&gt;一组有序项目的集合&gt;可变的数据类型【可进行增删改查】&gt;列表中可以包含任何数据类型，也可包含另一个列表【可任意组合嵌套】&gt;列表是以方括号“ []”包围的数据集合，不同成员以“ ,”分隔&gt;列表可通过序号访问其中成员 常见的列表操作声明&amp;创建123456l = [] #空列表l = [1, 2, 3, 4]l = [1, 'a', [2,3] ]l = list('hello') #得到 ['h', 'e', 'l', 'l', 'o'] l = list(range(4)) #[0, 1, 2, 3]l = '1,2,3,4,5'.split(',') #['1', '2', '3', '4', '5'] 内建函数list(a_sequence) 可以将一个序列转为列表 通过下标访问12&gt;&gt;&gt;l = [1, 2, 3, 4]&gt;&gt;&gt;l[0] #1 增加元素1234567891011A.新加入一个元素appendappend方法添加。它在原列表末尾添加一个 item， item类型可以是任意的l = [1, 2, 3]l.append('hello') #得到 [1, 2, 3, 'hello']l.append(['hello']) #得到 [1, 2, 3, 'hello', ['hello']]B.插入一个元素insertl1 = [1, 2, 3]l1.insert(1,9) #[1, 9, 2, 3] 删除元素 A.按item的索引或切片删除123l1 = [1, 2, 3, 4, 5, 6]del l1[0] #得到[2, 3, 4, 5, 6]del l1[0:2] #得到[4, 5, 6] B.按item的值进行删除123l1 = [1,2,3,1,2]l1.remove(1) #得到[2,3,1,2]若是remove对应值查无，将跑ValueError C.删除某个位置并返回该位置值12345pop若是不传位置参数，默认删除列表最后一个元素l1 = [1, 2, 3, 4, 5]a = l1.pop(1) #a=2b = l1.pop() #a=5 修改元素 A.某个元素12l1 = [1, 2, 3, 4]l1[0] = 0 #[0,2,3,4] B.某一段元素1234l1= [1,2,3,4]l1[0:2] = [7,8,9] #[7,8,9,3,4]l1[:] = [] #清空了 os &amp; shutilos 和 shutil模块常用操作12345678910111213141516171819202122232425262728293031323334353637os.sep 可以取代操作系统特定的路径分隔符。windows下为 '\\\\'os.name 字符串指示你正在使用的平台。比如对于Windows，它是'nt'，而对于Linux/Unix用户，它是 'posix'os.getcwd() 函数得到当前工作目录，即当前Python脚本工作的目录路径os.getenv() 获取一个环境变量，如果没有返回noneos.putenv(key, value) 设置一个环境变量值os.listdir(path) 返回指定目录下的所有文件和目录名os.remove(path) 函数用来删除一个文件os.system(command) 函数用来运行shell命令os.linesep 字符串给出当前平台使用的行终止符。例如，Windows使用 '\\r\\n'，Linux使用 '\\n' 而Mac使用 '\\r'os.path.split(path) 函数返回一个路径的目录名和文件名os.path.isfile() 和os.path.isdir()函数分别检验给出的路径是一个文件还是目录os.path.exists() 函数用来检验给出的路径是否真地存在os.curdir 返回当前目录 ('.')os.mkdir(path) 创建一个目录os.makedirs(path) 递归的创建目录os.chdir(dirname) 改变工作目录到dirname os.path.getsize(name) 获得文件大小，如果name是目录返回0Los.path.abspath(name) 获得绝对路径os.path.normpath(path) 规范path字符串形式os.path.splitext() 分离文件名与扩展名os.path.join(path,name) 连接目录与文件名或目录os.path.basename(path) 返回文件名os.path.dirname(path) 返回文件路径os.walk(top,topdown=True,onerror=None) 遍历迭代目录os.rename(src, dst) 重命名file或者directory src到dst 如果dst是一个存在的directory, 将抛出OSError. 在Unix, 如果dst在存且是一个file, 如果用户有权限的话，它将被安静的替换. 操作将会失败在某些Unix 中如果src和dst在不同的文件系统中. 如果成功, 这命名操作将会是一个原子操作 (这是POSIX 需要). 在 Windows上, 如果dst已经存在, 将抛出OSError，即使它是一个文件. 在unix，Windows中有效。os.renames(old, new) 递归重命名文件夹或者文件。像rename()# shutil 模块shutil.copyfile( src, dst) 从源src复制到dst中去。当然前提是目标地址是具备可写权限。抛出的异常信息为IOException. 如果当前的dst已存在的话就会被覆盖掉shutil.move( src, dst) 移动文件或重命名shutil.copymode( src, dst) 只是会复制其权限其他的东西是不会被复制的shutil.copystat( src, dst) 复制权限、最后访问时间、最后修改时间shutil.copy( src, dst) 复制一个文件到一个文件或一个目录shutil.copy2( src, dst) 在copy上的基础上再复制文件最后访问时间与修改时间也复制过来了，类似于cp –p的东西shutil.copy2( src, dst) 如果两个位置的文件系统是一样的话相当于是rename操作，只是改名；如果是不在相同的文件系统的话就是做move操作shutil.copytree( olddir, newdir, True/Flase)把olddir拷贝一份newdir，如果第3个参数是True，则复制目录时将保持文件夹下的符号连接，如果第3个参数是False，则将在复制的目录下生成物理副本来替代符号连接shutil.rmtree( src ) 递归删除一个目录以及目录内的所有内容 文件操作文件模式打开一个文件，返回一个文件对象。可以用open()或者file()，建议使用前者1234file_object = open(file_name, access_mode = ‘r’, buffering = -1) file_name：打开的文件名,若非当前路径，需指出具体路径mode:可选参数，文件打开模式 bufsize:可选参数，是否使用缓存 mode12345678910模式 描述r 以读方式打开文件，可读取文件信息.文件必须已存在w 以写方式打开文件，可向文件写入信息。存在则清空，不存在创建a 以追加方式打开文件，文件指针自动移到文件尾。追加r+ 以读写方式打开文件，可对文件进行读和写操作。w+ 消除文件内容，然后以读写方式打开文件。a+ 以读写方式打开文件，并把文件指针移到文件尾。b 以二进制模式打开文件，而不是以文本模式。该模式只对Windows或Dos有效，类Unix的文件是用二进制模式进行操作的U 通用换行符支持，任何系统下的文件, 不管换行符是什么, 使用U模式打开时, 换行符都会被替换为NEWLINE(\\n) bufsizebufsize取值 描述12340 禁用缓冲1 行缓冲，只缓冲一行大于1 指定缓冲区的大小，定制小于1 系统默认的缓冲区大小,m默认 文件对象属性123456file.name 文件名file.encoding文件使用编码,None 时使用系统默认编码file.mode Access文件打开时使用的额访问模式file.closed表文件已关闭，否则Falsefile.newlines未读取到分隔符时为None，包含行结束符的列表file.softspace为0表示在输出一数据后，加上一空格，1表示不加，内部使用 操作列表123456789101112131415161718#读file.read(size=-1) 从文件读取size个字节，未给定或为负，读取所有file.readline(size=-1) 读取并返回一行，或返回最大size个字符,包括\\nfile.readlines(sizeint=0) 读取所有行并返回列表，若给定sizeint&gt;0，返回总和大约为sizeint字节的行, 实际读取值可能比sizhint较大, 因为需要填充缓冲区#写file.write(str) 向文件中写入字符串(文本或二进制)file.writelines(seq) 写入多行，向文件中写入一个字符串列表，注意，要自己加入每行的换行符#其他file.seek(off,whence=0) 从文件中给移动指针，从whence(0起始，1当前，2末尾)偏移off个字节，正结束方向移动，负往开始方向移动file.tell() 返回当前文件中的位置。获得文件指针位置file.truncate(size=file.tell()) 截取文件到最大size个字节，默认为当前文件位置file.close() 关闭打开的文件,垃圾回收机制也会在文件对象的引用计数降至0的时候自动关闭文件file.fileno() 返回文件描述符(file descriptor FD 整型)是一个整数, 可以用在如os模块的read方法等一些底层操作上.file.flush() 刷新文件内部缓冲,直接把内部缓冲区的数据立刻写入文件, 而不是被动的等待输出缓冲区写入.file.isatty() 判断file是否是类tty设备file.next() 返回文件下一行 最佳实践1.养成手动close123456789101112f = open('a.py')……f.close()``` python2.读取大文件方法一:一次性读入,去左右空白+换行符，文件太大不建议这么做``` pythonf = open('bigdata')lines = [ line.strip() for line in f.readlines()] …..f.close() 方法二:迭代12345f = open('bigdata')for line in f: line = line.strip()…..f.close() 3.上下文管理器用with，等价与上面方法二，注意不用显式close123&gt;&gt;&gt; with open('a.py') as f:... for line in f:... line = line.strip() picklepickle任意python对象和字符串之间的序列化类似java序列化存储到文件的过程12345678910111213# encoding: utf-8import pickled = &#123;'a':1,'b':2&#125;f = open('datafile.pkl','wb')pickle.dump(d,f)f.close()f=open('datafile.pkl','rb')e=pickle.load(f)print e 其他相关模块123456789101112131415base64 二进制字符串和文本字符串之间的编码/解码操作binascii 二进制和ascii编码的二进制字符串间的编码/解码操作bz2 访问BZ2格式的压缩文件csv 访问csv文件(逗号分割文件)filecmp 用于比较目录和文件fileinput 提供多个文本文件的行迭代器getopt/optparse 提供了命令行参数的解析/处理glob/fnmatch 提供Unix样式的通配符匹配功能gzip/zlib 读写GNU zip(gzip)文件(压缩需要zlib模块)shutil 提供高级文件访问能力c/StringIO 对字符串对象提供类文件接口tarfile 读写TAR归档文件, 支持压缩文件tempfile 创建一个临时文件(名)uu 格式的编码和解码zipfile 用于读取ZIP归档文件的工具 参考：http://blog.csdn.net/wklken/article/details/6315514 Python 处理 ini 格式文件 | ConfigParser的使用ini文件格式概述ini 文件是文本文件，ini文件的数据格式一般为： 12345678[Section1 Name] KeyName1=value1 KeyName2=value2 ...[Section2 Name] KeyName1=value1 KeyName2=value2 ini 文件可以分为几个 Section，每个 Section 的名称用 [] 括起来，在一个 Section 中，可以有很多的 Key，每一个 Key 可以有一个值并占用一行，格式是 Key=value。 ConfigParser 类概述ConfigParser 可以用来读取ini文件的内容，如果要更新的话要使用 SafeConfigParser. ConfigParse 具有下面一些函数: 读取12345read(filename) 直接读取ini文件内容readfp(fp) 可以读取一打开的文件sections() 得到所有的section，并以列表的形式返回options(sections) 得到某一个section的所有optionget(section,option) 得到section中option的值，返回为string类型 写入 写入的话需要使用 SafeConfigParser, 因为这个类继承了ConfigParser的所有函数，而且实现了下面的函数:1set( section, option, value) 对section中的option进行设置 ConfigParser 使用例子1234567891011121314151617181920212223242526from ConfigParser import SafeConfigParserfrom StringIO import StringIO f = StringIO()scp = SafeConfigParser() print '-'*20, ' following is write ini file part ', '-'*20sections = ['s1','s2']for s in sections: scp.add_section(s) scp.set(s,'option1','value1') scp.set(s,'option2','value2') scp.write(f)print f.getvalue() print '-'*20, ' following is read ini file part ', '-'*20f.seek(0)scp2 = SafeConfigParser()scp2.readfp(f)sections = scp2.sections()for s in sections: options = scp2.options(s) for option in options: value = scp2.get(s,option) print \"section: %s, option: %s, value: %s\" % (s,option,value) 输出结果为： 123456789101112131415-------------------- following is write ini file part --------------------[s2]option2 = value2option1 = value1[s1]option2 = value2option1 = value1-------------------- following is read ini file part --------------------section: s2, option: option2, value: value2section: s2, option: option1, value: value1section: s1, option: option2, value: value2section: s1, option: option1, value: value1 os.path包含的函数1234&gt;&gt;&gt; import os&gt;&gt;&gt; import os.path&gt;&gt;&gt; dir(os.path)['__all__', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '_abspath_split', '_getfullpathname', 'abspath', 'altsep', 'basename', 'commonprefix', 'curdir', 'defpath', 'devnull', 'dirname', 'exists', 'expanduser', 'expandvars', 'extsep', 'genericpath', 'getatime', 'getctime', 'getmtime', 'getsize', 'isabs', 'isdir', 'isfile', 'islink', 'ismount', 'join', 'lexists', 'normcase', 'normpath', 'os', 'pardir', 'pathsep', 'realpath', 'relpath', 'sep', 'split', 'splitdrive', 'splitext', 'splitunc', 'stat', 'supports_unicode_filenames', 'sys', 'walk', 'warnings'] 获取路径名，文件名，扩展名12345678910111213&gt;&gt;&gt; path = \"d:/test/aaa/demo.txt\"获取目录名&gt;&gt;&gt; os.path.dirname(path)'d:/test/aaa'获取文件名带后缀&gt;&gt;&gt; os.path.basename(path)'demo.txt'分割路径名和文件名&gt;&gt;&gt; os.path.split(path)('d:/test/aaa', 'demo.txt')分割文件名和扩展民&gt;&gt;&gt; os.path.splitext(path)('d:/test/aaa/demo', '.txt') random12345678910111213141516171819202122232425262728293031323334353637随机整数：&gt;&gt;&gt; import random&gt;&gt;&gt; random.randint(0,99)# 21随机选取0到100间的偶数：&gt;&gt;&gt; import random&gt;&gt;&gt; random.randrange(0, 101, 2)# 42随机浮点数：&gt;&gt;&gt; import random&gt;&gt;&gt; random.random()0.85415370477785668&gt;&gt;&gt; random.uniform(1, 10)# 5.4221167969800881随机字符：&gt;&gt;&gt; import random&gt;&gt;&gt; random.choice('abcdefg&amp;#%^*f')# 'd'多个字符中选取特定数量的字符：&gt;&gt;&gt; import randomrandom.sample('abcdefghij', 3)# ['a', 'd', 'b']多个字符中选取特定数量的字符组成新字符串：&gt;&gt;&gt; import random&gt;&gt;&gt; import string&gt;&gt;&gt; string.join( random.sample(['a','b','c','d','e','f','g','h','i','j'], 3) ).replace(\" \",\"\")# 'fih'随机选取字符串：&gt;&gt;&gt; import random&gt;&gt;&gt; random.choice ( ['apple', 'pear', 'peach', 'orange', 'lemon'] )# 'lemon'洗牌：&gt;&gt;&gt; import random&gt;&gt;&gt; items = [1, 2, 3, 4, 5, 6]&gt;&gt;&gt; random.shuffle(items)&gt;&gt;&gt; items# [3, 2, 5, 6, 4, 1] xrange 和 range12345678910111213141516171819202122232425262728293031323334353637383940414243444546range 函数说明：range([start,] stop[, step])，根据start与stop指定的范围以及step设定的步长，生成一个序列。range示例:&gt;&gt;&gt; range(5)[0, 1, 2, 3, 4]&gt;&gt;&gt; range(1,5)[1, 2, 3, 4]&gt;&gt;&gt; range(0,6,2)[0, 2, 4]xrange 函数说明：用法与range完全相同，所不同的是生成的不是一个数组，而是一个生成器。xrange示例:&gt;&gt;&gt; xrange(5)xrange(5)&gt;&gt;&gt; list(xrange(5))[0, 1, 2, 3, 4]&gt;&gt;&gt; xrange(1,5) xrange(1, 5)&gt;&gt;&gt; list(xrange(1,5))[1, 2, 3, 4]&gt;&gt;&gt; xrange(0,6,2)xrange(0, 6, 2)&gt;&gt;&gt; list(xrange(0,6,2))[0, 2, 4]由上面的示例可以知道：要生成很大的数字序列的时候，用xrange会比range性能优很多，因为不需要一上来就开辟一块很大的内存空间，这两个基本上都是在循环的时候用：for i in range(0, 10): print ifor i in xrange(0, 10): print i这两个输出的结果都是一样的，实际上有很多不同，range会直接生成一个list对象：a = range(0,10)print type(a)print aprint a[0], a[1]输出结果：&lt;type 'list'&gt;[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]0 1而xrange则不会直接生成一个list，而是每次调用返回其中的一个值：a = xrange(0,100)print type(a)print aprint a[0], a[1]输出结果：&lt;type 'xrange'&gt;xrange(100)0 1 python 实现ftp上传下载http://www.ifunsion.com/archives/2597 urllib &amp; urllib21、Proxy 的设置urllib2 默认会使用环境变量 http_proxy 来设置 HTTP Proxy。如果想在程序中明确控制 Proxy，而不受环境变量的影响，可以使用下面的方式123456789import urllib2enable_proxy = Trueproxy_handler = urllib2.ProxyHandler(&#123;\"http\" : 'http://some-proxy.com:8080'&#125;)null_proxy_handler = urllib2.ProxyHandler(&#123;&#125;)if enable_proxy: opener = urllib2.build_opener(proxy_handler)else: opener = urllib2.build_opener(null_proxy_handler) urllib2.install_opener(opener) 这里要注意的一个细节，使用 urllib2.install_opener() 会设置 urllib2 的全局 opener。这样后面的使用会很方便，但不能做更细粒度的控制，比如想在程序中使用两个不同的 Proxy 设置等。比较好的做法是不使用 install_opener 去更改全局的设置，而只是直接调用 opener 的 open 方法代替全局的 urlopen 方法。 2、Timeout 设置在老版本中，urllib2 的 API 并没有暴露 Timeout 的设置，要设置 Timeout 值，只能更改 Socket 的全局 Timeout 值。1234import urllib2import socketsocket.setdefaulttimeout(10) # 10 秒钟后超时urllib2.socket.setdefaulttimeout(10) # 另一种方式 在新的 Python 2.6 版本中，超时可以通过 urllib2.urlopen() 的 timeout 参数直接设置。12import urllib2response = urllib2.urlopen(&apos;http://www.google.com&apos;, timeout=10) 3、在 HTTP Request 中加入特定的 Header要加入 Header，需要使用 Request 对象：1234import urllib2request = urllib2.Request(uri)request.add_header('User-Agent', 'fake-client')response = urllib2.urlopen(request) 对有些 header 要特别留意，Server 端会针对这些 header 做检查User-Agent 有些 Server 或 Proxy 会检查该值，用来判断是否是浏览器发起的 RequestContent-Type 在使用 REST 接口时，Server 会检查该值，用来确定 HTTP Body 中的内容该怎样解析。常见的取值有：123application/xml ：在 XML RPC，如 RESTful/SOAP 调用时使用application/json ：在 JSON RPC 调用时使用application/x-www-form-urlencoded ：浏览器提交 Web 表单时使用 在使用 RPC 调用 Server 提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致 Server 拒绝服务。 4、Redirecturllib2 默认情况下会针对 3xx HTTP 返回码自动进行 Redirect 动作，无需人工配置。要检测是否发生了 Redirect 动作，只要检查一下 Response 的 URL 和 Request 的 URL 是否一致就可以了。123import urllib2response = urllib2.urlopen('http://www.google.cn')redirected = response.geturl() == 'http://www.google.cn' 如果不想自动 Redirect，除了使用更低层次的 httplib 库之外，还可以使用自定义的 HTTPRedirectHandler 类。12345678import urllib2class RedirectHandler(urllib2.HTTPRedirectHandler): def http_error_301(self, req, fp, code, msg, headers): pass def http_error_302(self, req, fp, code, msg, headers): passopener = urllib2.build_opener(RedirectHandler)opener.open('http://www.google.cn') 5、Cookieurllib2 对 Cookie 的处理也是自动的。如果需要得到某个 Cookie 项的值，可以这么做：12345678import urllib2import cookielibcookie = cookielib.CookieJar()opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))response = opener.open('http://www.google.com')for item in cookie: if item.name == 'some_cookie_item_name': print item.value 6、使用 HTTP 的 PUT 和 DELETE 方法urllib2 只支持 HTTP 的 GET 和 POST 方法，如果要使用 HTTP PUT 和 DELETE，只能使用比较低层的 httplib 库。虽然如此，我们还是能通过下面的方式，使 urllib2 能够发出 HTTP PUT 或 DELETE 的包：1234import urllib2request = urllib2.Request(uri, data=data)request.get_method = lambda: 'PUT' # or 'DELETE'response = urllib2.urlopen(request) 这种做法虽然属于 Hack 的方式，但实际使用起来也没什么问题。 7、得到 HTTP 的返回码对于 200 OK 来说，只要使用 urlopen 返回的 response 对象的 getcode() 方法就可以得到 HTTP 的返回码。但对其它返回码来说，urlopen 会抛出异常。这时候，就要检查异常对象的 code 属性了：12345import urllib2try: response = urllib2.urlopen('http://restrict.web.com')except urllib2.HTTPError, e: print e.code 8、Debug Log使用 urllib2 时，可以通过下面的方法把 Debug Log 打开，这样收发包的内容就会在屏幕上打印出来，方便我们调试，在一定程度上可以省去抓包的工作。123456import urllib2httpHandler = urllib2.HTTPHandler(debuglevel=1)httpsHandler = urllib2.HTTPSHandler(debuglevel=1)opener = urllib2.build_opener(httpHandler, httpsHandler)urllib2.install_opener(opener)response = urllib2.urlopen('http://www.google.com')","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"git 基础用法和命令","slug":"2013-05-11-git","date":"2017-07-06T08:02:32.000Z","updated":"2017-09-20T08:55:18.000Z","comments":true,"path":"2017/07/06/2013-05-11-git/","link":"","permalink":"http://yoursite.com2017/07/06/2013-05-11-git/","excerpt":"","text":"本文是《git权威指南》和《pro git》的读书笔记。主要是一些命令的记录和对一些概念的理解。讲解的非常详细，强烈推荐这两本书。 爱上Git的理由 每日工作备份 异地协同办公 现场版本控制 所谓现场版本控制，就是在客户现场或在产品部署的现场进行源代码的修改，并在修改过程中进行版本控制，以便在完成修改后能够将修改结果甚至修改过程一并带走，并能够将修改结果合并至项目对应的代码库中。 避免引入辅助目录 比如svn在每一个目录下都创建了.svn目录 git 起步三种状态git 管理项目时，文件流转的三个工作区域：git本地数据目录，工作目录以及暂存区域。任何一个文件在Git内部都只有三种状态： committed(已提交) modified(已修改) staged(已暂存) 常用命令git 配置git config可以用来配置和读取相应的工作环境变量。变量存放与三个地方： /etc/gitconfig文件：系统中对所有用户都使用的配置，配置时添加–system选项。 ~/.gitconfig：用户目录下的配置文件适用于该用户。配置时使用–global选项。 .git/config：当前项目的git目录中的配置文件，仅对当前项目有效。 命令示例： git config --global user.name &quot;xiyang&quot; git config --global user.email &quot;sdlgxxy@gmail.com&quot; git config --global color.ui true git config --global alias.co checkout git config --global alias.ci commit git config --global alias.st status git config --global alias.br branch git config --global core.editor &quot;vim&quot; git config --global merge.tool &quot;vimdiff&quot; git config --list 查看已有的配置信息 基础命令查看/添加/提交/删除/找回/重置修改文件 git help &lt;command&gt; # 显示command的help git show # 显示某次提交的内容 git show $id git co -- &lt;file&gt; # 抛弃工作区修改 git co . # 抛弃工作区修改 git add &lt;file&gt; # 将工作文件修改提交到本地暂存区 git add . # 将所有修改过的工作文件提交暂存区 git rm &lt;file&gt; # 从版本库中删除文件 git rm &lt;file&gt; --cached # 从版本库中删除文件，但不删除文件 git reset &lt;file&gt; # 从暂存区恢复到工作文件 git reset -- . # 从暂存区恢复到工作文件 git reset --hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改 git ci &lt;file&gt; git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做 git ci -am &quot;some comments&quot; git ci --amend # 修改最后一次提交记录 git revert &lt;$id&gt; # 恢复某次提交的状态，恢复动作本身也创建了一次提交对象 git revert HEAD # 恢复最后一次提交的状态 git init可以初始化版本库，执行git add 将文件放到暂存区，git commit后提交文件到版本库。 设置忽略某些文件如果某些文件无需纳入 git 的管理，也不希望他们总出现untracked列表中。可以创建一个.gitignore文件。 # 注释行 *.pyc # 忽略所有的pyc文件 !lib.pyc # lib.pyc除外 /TODO # 忽略根目录下的TODO文件 build/ # 忽略build目录下所有的文件 doc/*.txt # doc目录下所有的txt文件 git diffgit diff B A 比较里程碑B和里程碑A git diff A 比较工作区和里程碑A git diff --cached A 比较暂存区和里程碑A git diff 比较工作区和暂存区 git diff --cached 比较暂存区额HEAD git diff HEAD 比较工作区和HEAD 查看提交日志git log git log --pretty=fuller git log &lt;file&gt; # 查看该文件每次提交记录 git log -p &lt;file&gt; # 查看每次详细修改内容的diff git log -p -2 # 查看最近两次详细修改 git log --stat # 查看提交统计信息 暂存区git stash 保存当前的工作进度，会分别对暂存区和工作区的状态进行保存。 git stash list 显示进度列表 git stash pop 恢复最近保存的工作进度 git stash save &quot;message&quot; 保存工作进度的同时，指定说明 git stash drop [&lt;stash&gt;] 删除一个存储进度 git stash clear 删除所有存储的进度 git stash branch &lt;btanchname&gt; &lt;stash&gt; 基于进度创建分支 重置操作git reset / git rest HAED 使用HEAD执行的目录树重置暂存区，工作区不受影响 git reset --soft HEAD^ 工作区和暂存区不改变，但是引用向前回退一次 git reset HEAD^ 工作区不改变，暂存区回退到上一次提交之前 git reset --mixed HEAD^ 同上 git reset --hard HEAD^ 彻底撤销最近提交。引用回退到前一次，工作区和暂存区都改变。 git 本地分支管理查看/切换/创建和删除分支 git br -r # 查看远程分支 git br &lt;new_branch&gt; # 创建新的分支 git br -v # 查看各个分支最后提交信息 git br --merged # 查看已经被合并到当前分支的分支 git br --no-merged # 查看尚未被合并到当前分支的分支 git co &lt;branch&gt; # 切换到某个分支 git co -b &lt;new_branch&gt; # 创建新的分支，并且切换过去 git co -b &lt;new_branch&gt; &lt;branch&gt; # 基于branch创建新的new_branch git co $id # 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除 git co $id -b &lt;new_branch&gt; # 把某次历史提交记录checkout出来，创建成一个分支 git br -d &lt;branch&gt; # 删除某个分支 git br -D &lt;branch&gt; # 强制删除某个分支 (未被合并的分支被删除的时候需要强制) 分支合并和rebase git merge &lt;branch&gt; # 将branch分支合并到当前分支 git merge origin/master --no-ff # 不要Fast-Foward合并，这样可以生成merge提交 git rebase master &lt;branch&gt; # 将master rebase到branch，相当于： git co &lt;branch&gt; &amp;&amp; git rebase master &amp;&amp; git co master &amp;&amp; git merge &lt;branch&gt; o git 远程分支管理git pull # 抓取远程仓库所有分支更新并合并到本地 git pull --no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并 git fetch origin # 抓取远程仓库更新 git merge origin/master # 将远程主分支合并到本地当前分支 git co --track origin/branch # 跟踪某个远程分支创建相应的本地分支 git co -b &lt;local_branch&gt; origin/&lt;remote_branch&gt; # 基于远程分支创建本地分支，功能同上 git push # push所有分支 git push origin master # 将本地主分支推到远程主分支 git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库) git push origin &lt;local_branch&gt; # 创建远程分支， origin是远程仓库名 git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; # 创建远程分支 git push origin :&lt;remote_branch&gt; #先删除本地分支(git br -d &lt;branch&gt;)，然后再push删除远程分支 git 远程仓库管理git remote -v # 查看远程服务器地址和仓库名称 git remote show origin # 查看远程服务器仓库状态 git remote add origin git@github:robbin/robbin_site.git # 添加远程仓库地址 git remote set-url origin git@github.com:robbin/robbin_site.git # 设置远程仓库地址(用于修改远程仓库地址) git remote rm &lt;repository&gt; # 删除远程仓库 git blame文件追溯 删除版本库中没有引用的对象 如果不小心把一些无用的文件提交到暂存区，撤回后文件并没有从版本库中上删除，可以使用如下命令清理。 git fsck 查看版本库中包含的没有被任何引用关联的松散对象 git prune 清理这些对象 git 里程碑git tag &lt;tagname&gt; [&lt;commit&gt;] git tag -a &lt;tagname&gt; [&lt;commit&gt;] git tag -m &lt;msg&gt; &lt;tagname&gt; [&lt;commit&gt;] git tag -s &lt;tagname&gt; [&lt;commit&gt;] git tag -u &lt;key-id&gt; &lt;tagname&gt; [&lt;commit&gt;]","categories":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/categories/工具/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"论工具的重要性","slug":"论工具的重要性","date":"2017-06-14T01:38:30.000Z","updated":"2017-09-14T14:55:33.000Z","comments":true,"path":"2017/06/14/论工具的重要性/","link":"","permalink":"http://yoursite.com2017/06/14/论工具的重要性/","excerpt":"","text":"最近看了一篇文章:《顶级程序员和普通程序员在思维模式上的5个区别！》 《The Effective Engineer》的作者在写书的过程中，为了了解那些顶级程序员和普通程序员的区别，采访了很多硅谷顶级科技公司的顶尖软件工程师。他发现这些给世界带来巨大影响的的工程师们至少有以下5个共同的思维模式： 1.勇于去研究你不懂的代码 2.精通代码调试(debug) 3.重视能够节约时间的工具 4.优化你的迭代速度 5.系统性的思考方式 其中第三条 重视能够节约时间的工具 带给我很多启发 曾经在Facebook担任技术总监的Bobby Johnson描述过，高效率的程序员都把时间花在制作工具上。很多人也认为工具是很重要的，但是他们并没有花时间去制作、整合自己的工具。但是，Jonson团队最出色的员工耗费了他们1/3的时间在工具制作上，这些工具可以用来发布代码，监控系统，以及能让他们花更少的时间去做更多事情。总之，不要花时间去做机器可以代替你去做的事情。 对于大部分初级工程师来说，大部分的工作内容都是一些重复的业务代码，如果只是被动的编写业务，可能很难有长进，很多人会抱怨整天就是写增删改查的代码，没有技术含量，不能学到新东西，殊不知工作中大部分就是这样的工作。 infoQ负责出品的王概凯写的&lt;&lt;聊聊架构&gt;&gt;第一篇关于生命周期最后有一段话： 非核心生命周期拆分出来成为服务后，这个服务不再仅仅给一个人使用，而变成了所有人能能够共享。非核心生命周期一旦拆分出来后，往往就变成了一个通用的服务，反而获得了更大的生命力，不再局限于原有的大生命周期。对非核心生命周期的掌握，慢慢也就成为了一个一个的职业。而原有的大生命周期则变的更加精简，可以更加专注于自己的核心生命周期活动，以节省更多的时间。 在日常的后台开发中，会有很多通用的需求，是每次遇到复制拷贝一份代码快速实现功能呢，还是可以抽取出一个公共服务或通用的组件提供给大家使用呢？ 假如仅仅为了实现需求，正好自己以前写过类似或则网上有别人的代码，然后自己复制拷贝一份，长远来看其实是一直在做重复的工作，也很难有成长，假如同样的事情做了5遍，10遍充其量你也只是比别人熟练一下而已。 那工作中有哪些是通用的并且是可以抽取出来的功能呢？或者说是非核心生命周期。考虑如下的几个场景： 后台文件导出文件导出是一个通用的需求且很常见，在日常的开发中此类的需求和开发会非常频繁，常见的做法是引入POI的包，从数据库中获取到数据，然后调用POI的接口生成excel文件，输出给浏览器。 需要手工做一次java对象到excel列的映射，如果需求字段有变更，一般情况下需要修改代码上线。 假如导出的数据量特别大，后台也比较耗时，则同步的方式很容易造成超时，一般会做成异步导出，异步下载，则需要很多额外的开发，假如有多个系统都需要，那就需要在多个系统都实现一遍。 假如导出的服务在线上的应用中，大量频繁的导出会请求到数据库主库上，会给数据库造成很大的压力，这个时候需要做读写分离。假如需要占用很多内存，有可能影响线上业务，则需要对导出做服务拆分。 另外还有跨数据库访问的问题。是不是可以在接到这种需求的时候不需要写代码，基于配置式完成功能呢？ 调度系统我们知道java中使用quartz可以很方便的配置定时调度，但是很多定时任务都要求在同一时间只能有一个任务执行。如何保证呢？方法有很多。但是是不是可以提供一个调度系统可以让各业务系统不需要都自己实现一套。 业务监控报警分布式系统中分布式事务问题是一个通用的问题，很难去保证在分布式系统下多个系统的一致性问题，一般业界的通用做法是保证数据的最终一致性。 但是如何发现业务的异常呢？比如订单在支付系统支付成功，但是订单平台支付状态还是未支付。 代码生成在很多的创业公司，或中小型项目开发的公司，会面临大量新系统的开发，每次搭建项目的基础代码都会非常耗费时间，而且里面有大量的配置文件和配置项。如何快速生成项目模板，省去基础的框架配置呢？ 以上的四个场景在我们当前的公司都有独立的系统和工具去支撑对应的需求，每一个系统在不断的迭代过程中都焕发了自己更强大的生命力。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/tags/工具/"}]},{"title":"jsonp 解决跨域请求","slug":"jsonp解决跨域请求","date":"2017-01-12T01:08:28.000Z","updated":"2017-09-15T03:19:12.000Z","comments":true,"path":"2017/01/12/jsonp解决跨域请求/","link":"","permalink":"http://yoursite.com2017/01/12/jsonp解决跨域请求/","excerpt":"","text":"什么是跨域请求浏览器的同源策略限制从一个源加载的文档或脚本与来自另一个源的资源进行交互。如果协议，端口和主机对于两个页面是相同的，则两个页面具有相同的源，否则就是不同源的。如果要在js里发起跨域请求，则要进行一些特殊处理了。 解决方案最简单的有两种解决方式： 可以把请求发到自己的服务端，再通过后台代码发起请求，再将数据返回前端。 使用jsonp 第一种需要在服务器端做额外开发，而且频繁修改也需要频繁的改服务器端，一般不建议使用。下面看一下使用jsonp解决跨域问题的解决方案： 什么是jsonpJSONP 和 JSON 看着很像，他们分别是什么呢？ JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。对于JSON大家应该是很了解了吧，不是很清楚的朋友可以去json.org上了解下，简单易懂。 JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式）。 实现演示前端代码1234567891011121314$.ajax(&#123; type: \"get\", async: false, url: \"http://wukong.iqdnet.cn/wukongbg/admin/monitorList/test\", dataType: \"jsonp\", jsonp: \"callbackparam\",//传递给请求处理程序或页面的，用以获得jsonp回调函数名的参数名(一般默认为:callback) success: function(json)&#123; console.log(json); alert(json); &#125;, error: function()&#123; alert('fail'); &#125; &#125;); 服务器端在controller中定义一个方法 test 返回JSON的数据 123456789101112131415161718192021/** * test */@RequestMapping(value = \"test\",method= RequestMethod.GET)@ResponseBodypublic Object test(String callbackparam,HttpServletRequest request,MonitorListParams monitorListParams) &#123; logger.info(\"find monitorList list.\"); System.out.println(System.getProperty(\"env\")); ModelResult modelResult = new ModelResult(ModelResult.CODE_200); ResultPage&lt;MonitorList&gt; resultPage = null; resultPage = monitorListService.getResultPage(monitorListParams); modelResult.setMessage(\"查询成功\"); modelResult.setResultPage(resultPage); String content = JSON.toJSONString(modelResult); content = callbackparam +\"(\"+content+\")\"; return content;&#125; 效果 参考Jquery 文档","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"jsonp 跨域","slug":"jsonp-跨域","permalink":"http://yoursite.com/tags/jsonp-跨域/"}]},{"title":"HashMap 详解和源码解析","slug":"06-深入研究java基础-HashMap","date":"2016-10-21T10:12:53.000Z","updated":"2017-09-14T08:31:51.000Z","comments":true,"path":"2016/10/21/06-深入研究java基础-HashMap/","link":"","permalink":"http://yoursite.com2016/10/21/06-深入研究java基础-HashMap/","excerpt":"","text":"概述123public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 类图结构 http://yikun.github.io/2015/04/01/Java-HashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/ http://www.cnblogs.com/skywang12345/p/3323085.html","categories":[{"name":"java 集合","slug":"java-集合","permalink":"http://yoursite.com/categories/java-集合/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"深入研究java.lang.Object类","slug":"2016-10-21-java基础-深入研究java-lang-Object类","date":"2016-10-21T06:52:09.000Z","updated":"2017-09-21T06:08:53.000Z","comments":true,"path":"2016/10/21/2016-10-21-java基础-深入研究java-lang-Object类/","link":"","permalink":"http://yoursite.com2016/10/21/2016-10-21-java基础-深入研究java-lang-Object类/","excerpt":"","text":"Object类是所有类的基类尽管Object 类是一个具体类，但是设计他主要是为了扩展。他所有的非final方法（equals、hashcode、tostring、clone和finalize）都有明确的通用约定，因为他们被设计成是要被覆盖的。任何一个类，在覆盖这些方法的时候，都有责任遵守这些通用约定，如果不能做到这一点，其它依赖月这些约定的类（例如HashMap和HashSet）就无法结合该类一起正常工作。 Object包含如下API Object() 默认构造方法 clone() 创建并返回此对象的一个副本。 equals(Object obj) 指示某个其他对象是否与此对象“相等”。 finalize() 当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。 getClass() 返回一个对象的运行时类。 hashCode() 返回该对象的哈希码值。 notify() 唤醒在此对象监视器上等待的单个线程。 notifyAll() 唤醒在此对象监视器上等待的所有线程。 toString() 返回该对象的字符串表示。 wait() 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。 wait(long timeout) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。 wait(long timeout, int nanos) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。 方法详解equals 用来判断两个对象是否相等==与equals在Java中经常被使用，大家也都知道==与equals的区别：==表示的是变量值完成相同（对于基础类型，地址中存储的是值，引用类型则存储指向实际对象的地址）；equals表示的是对象的内容完全相同，此处的内容多指对象的特征/属性。 实际上，上面说法是不严谨的，更多的只是常见于String类中。首先看一下Object类中关于equals()方法的定义：jdk的默认实现是用 == 来实现的,直接比较的内存地址。 123public boolean equals(Object obj) &#123; return (this == obj);&#125; 由此可见，Object原生的equals()方法内部调用的正是==，与==具有相同的含义。既然如此，为什么还要定义此equals()方法？ equlas()方法的正确理解应该是：判断两个对象是否相等。那么判断对象相等的标尺又是什么？ 如上，在object类中，此标尺即为==。当然，这个标尺不是固定的，其他类中可以按照实际的需要对此标尺含义进行重定义。如String类中则是依据字符串内容是否相等来重定义了此标尺含义。如此可以增加类的功能型和实际编码的灵活性。当然了，如果自定义的类没有重写equals()方法来重新定义此标尺，那么默认的将是其父类的equals()，直到object基类。 Java语言规范要求equals方法具有下面的特点： jdk 中的注释如下： 翻译过来有下面的几个规则： 自反性：对于任何非空引用值 x，x.equals(x) 都应返回 true。 对称性：对于任何非空引用值 x 和 y，当且仅当 y.equals(x) 返回 true 时，x.equals(y) 才应返回 true。 传递性：对于任何非空引用值 x、y 和 z，如果 x.equals(y) 返回 true，并且 y.equals(z) 返回 true，那么 x.equals(z) 应返回 true。 一致性：对于任何非空引用值 x 和 y，多次调用 x.equals(y) 始终返回 true 或始终返回 false，前提是对象上 equals 比较中所用的信息没有被修改。 对于任何非空引用值 x，x.equals(null) 都应返回 false String 类重写了equals方法，如下：123456789101112131415161718192021222324252627282930313233343536/** * Compares this string to the specified object. The result is &#123;@code * true&#125; if and only if the argument is not &#123;@code null&#125; and is a &#123;@code * String&#125; object that represents the same sequence of characters as this * object. * * @param anObject * The object to compare this &#123;@code String&#125; against * * @return &#123;@code true&#125; if the given object represents a &#123;@code String&#125; * equivalent to this string, &#123;@code false&#125; otherwise * * @see #compareTo(String) * @see #equalsIgnoreCase(String) */public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; toString 方法toString()方法返回该对象的字符串表示。先看一下Object中的具体方法体： 123public String toString() &#123; return getClass().getName() + \"@\" + Integer.toHexString(hashCode());&#125; toString()方法相信大家都经常用到，即使没有显式调用，但当我们使用System.out.println(obj)时，其内部也是通过toString()来实现的。 getClass()返回对象的类对象，getClassName()以String形式返回类对象的名称（含包名）。Integer.toHexString(hashCode())则是以对象的哈希码为实参，以16进制无符号整数形式返回此哈希码的字符串表示形式。 如上例中的u1的哈希码是638，则对应的16进制为27e，调用toString()方法返回的结果为：com.corn.objectsummary.User@27e。 因此：toString()是由对象的类型和其哈希码唯一确定，同一类型但不相等的两个对象分别调用toString()方法返回的结果可能相同。 我们做实验打印某个类如下所示1234567891011121314User u1 = new User();u1.setName(\"u1\");User u2 = new User();u2.setName(\"u2\");System.out.println(\"u1--&gt; \" + u1);System.out.println(\"u2--&gt; \" + u2);输出u1--&gt; com.xiyang.study.reflect.User@99fad95cu2--&gt; com.xiyang.study.reflect.User@cee1149du1--&gt; com.xiyang.study.reflect.User@99fad95cu2--&gt; com.xiyang.study.reflect.User@cee1149d hashcode1public native int hashCode(); 以下是关于HashCode的官方文档定义： hashcode方法返回该对象的哈希码值。支持该方法是为哈希表提供一些优点，例如，java.util.Hashtable 提供的哈希表。 hashCode 的常规协定是： 在 Java 应用程序执行期间，在同一对象上多次调用 hashCode 方法时，必须一致地返回相同的整数，前提是对象上 equals 比较中所用的信息没有被修改。从某一应用程序的一次执行到同一应用程序的另一次执行，该整数无需保持一致。如果根据 equals(Object) 方法，两个对象是相等的，那么在两个对象中的每个对象上调用 hashCode 方法都必须生成相同的整数结果。以下情况不是必需的：如果根据 equals(java.lang.Object) 方法，两个对象不相等，那么在两个对象中的任一对象上调用 hashCode 方法必定会生成不同的整数结果。但是，程序员应该知道，为不相等的对象生成不同整数结果可以提高哈希表的性能。实际上，由 Object 类定义的 hashCode 方法确实会针对不同的对象返回不同的整数。（这一般是通过将该对象的内部地址转换成一个整数来实现的，但是 JavaTM 编程语言不需要这种实现技巧。） 以上这段官方文档的定义，我们可以抽取出以下几个关键点：1、hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的；2、如果两个对象相同（x.equals(y)），那么这两个对象的hashCode一定要相同；3、如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点；4、两个对象的hashCode相同，并不一定表示两个对象就相同，只能够说明这两个对象在散列存储结构中，他们“存放在同一个篮子里”。 再归纳一下就是hashCode是用于查找使用的，而equals是用于比较两个对象的是否相等的。 结合HashMap的实现可以很好的理解这个概念。如下是HashMap的数据结构: table 数组代表了桶，每一个桶里可能会存放不止一个元素，如果两个对象的hash值相等，就会放到一个桶里，用链表存放。但是这两个对象并不一定相当，所以这也解释了为什么hashcode相等的两个对象并不一定相等。 既然比较两个对象是否相等的唯一条件（也是冲要条件）是equals，那么为什么还要弄出一个hashCode()，并且进行如此约定，弄得这么麻烦？其实，这主要体现在hashCode()方法的作用上，其主要用于增强哈希表的性能。 以集合类中，以Set为例，当新加一个对象时，需要判断现有集合中是否已经存在与此对象相等的对象，如果没有hashCode()方法，需要将Set进行一次遍历，并逐一用equals()方法判断两个对象是否相等，此种算法时间复杂度为o(n)。通过借助于hasCode方法，先计算出即将新加入对象的哈希码，然后根据哈希算法计算出此对象的位置，直接判断此位置上是否已有对象即可。（注：Set的底层用的是Map的原理实现） 在此需要纠正一个理解上的误区：对象的hashCode()返回的不是对象所在的物理内存地址。甚至也不一定是对象的逻辑地址，hashCode()相同的两个对象，不一定相等，换言之，不相等的两个对象，hashCode()返回的哈希码可能相同。 为什么重写了equals 还要重写 hashCode方法？在 hashcode 方法中有一个原则：如果两个对象相同，即x.equals(y)为true, 那么这两个对象的hashCode一定要相同。 假如你自己的类不重写hashCode，那就会使用 Object 类的 hashCode 返回这个类的hashcode值，Object默认返回这个对象存储的内存地址的编号，那么有可能会导致两个对象equals返回为true，但是却有不同的hashcode码。 如何重写equals 和 hashCode 方法不建议自己实现，借助IDE可以很容易的实现一个类的equals 和 hashCode方法，比如我们定义一个类如下：12345678910/** * Created by xiexiyang on 16/5/3. */public class Member&#123; private String name; private Integer age; private int status;&#125; IDE 辅助生成的 equals 和 hashCode 如下所示：1234567891011121314151617181920212223@Overridepublic boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Member member = (Member) o; if (status != member.status) return false; if (name != null ? !name.equals(member.name) : member.name != null) return false; if (age != null ? !age.equals(member.age) : member.age != null) return false; return true;&#125;@Overridepublic int hashCode() &#123; int result = name != null ? name.hashCode() : 0; result = 31 * result + (age != null ? age.hashCode() : 0); result = 31 * result + status; return result;&#125;注：上述hashCode()的重写中出现了result*31，是因为result*31 = (result&lt;&lt;5) - result。之所以选择31，是因为左移运算和减运算计算效率远大于乘法运算。当然，也可以选择其他数字。 notify notifyAll wait clone 都是native的方法，依赖于底层的实现","categories":[{"name":"java 基础","slug":"java-基础","permalink":"http://yoursite.com/categories/java-基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"java 集合类概述","slug":"01-java集合类概述","date":"2016-08-05T03:58:13.000Z","updated":"2017-09-14T08:32:09.000Z","comments":true,"path":"2016/08/05/01-java集合类概述/","link":"","permalink":"http://yoursite.com2016/08/05/01-java集合类概述/","excerpt":"","text":"在java中一切皆是对象，集合就是盛放对象的容器，根据不同的数据结构（集合、链表、队列、栈、数组、映射等）对应不同的集合类。java的集合类都在java.util包下。为了处理多线程环境下的并发安全问题，java5还在java.util.concurrent包下提供了一些多线程支持的集合类。本文暂不包含并发集合包。 java 集合主要可以分为如下4个部分：List列表、Set集合、Map映射和工具类（Iterator迭代器、Enumeration枚举类、Arrays和Collections）。如下图所示： 整体的框架图如下： 梳理出主干我们常用的集合类如下： 最主要的两个接口 Collection 和 Map 1 、 Collections 包含了 List 和 Set 两种不同的数据集合。 List 是一个有序的队列，包含了常用的 ArrayList，LinkedList、Vector和Stack 类。 Set 是一个不允许重复元素的集合，包含有 HashSet、TreeSet。HashSet依赖于HashMap，TreeSet依赖于TreeMap 2、 Map 是表示键值对映射的结构。 AbstractMap 是一个抽象类，它实现了Map接口中的大部分API，而HashMap、TreeMap、WeakHashMap都是继承于AbstractMap。HashTable继承于Dictionary，但它实现了Map接口。 Arrays 和 Collections 是两个常用的工具类。","categories":[{"name":"java 集合","slug":"java-集合","permalink":"http://yoursite.com/categories/java-集合/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"我的读书史","slug":"我的读书史","date":"2016-03-14T08:48:02.000Z","updated":"2017-09-14T10:31:19.000Z","comments":true,"path":"2016/03/14/我的读书史/","link":"","permalink":"http://yoursite.com2016/03/14/我的读书史/","excerpt":"","text":"一本好书，往往一开始会读的特别快，临到最后反而舍不得读完。读罢，故事里面的人和事，萦萦于脑畔，飘着飘着，慢慢的尘封于一处。 启蒙小的时候可供娱乐的东西很少，不像现在的小孩子在2、3岁的时候，父母就会给孩子买一些绘本启蒙，我是到了小学认字之后才开始看一些”课外书“，而且当时可供阅读的书也很少，好的书就更少了。 小学四五年级的时候，同学中开始流传一些课外书，比较正统的《格林童话》《安徒生童话》《一千零一夜》《十万个为什么》《伊索寓言》，大都是需要借同学的看，我看书比较快，这些书很快就看完了，看的多了发现很多神话故事框架大都很相似，那个时候自己无聊也会给妹妹编一些神话故事听。 那个时候学校里还流传着一些《故事会》《鬼故事》《十八层地狱》之类的一些书，书不大也很薄，一本书大约5毛钱的样子，大都是一些员外，书生小姐，妖狐之类的故事。当时也是饥不择食，几乎什么都看，当然这些书看的时候不能被大人看见，所以只能偷偷的看，有时候看的入迷到了晚上就拿手电筒躲在被窝中看书，所以导致现在眼睛近视加散光，离开眼镜整个世界都是模糊的。 即使这样仍然还是会有没书看的时候，记得以前的日历上每页都会有一些小故事，所以也会找些日历来看，报纸的中缝也会有很多小故事，自己也会拿来看，伯父家里有订阅的报纸，有时候去伯父家的时候，也会拿报纸过来找里面的故事看。 后来大伯父发现了我喜欢看书，当时他在我们小学当校长，暑假的时候就帮我从学校图书馆借了一些书回来。然后我就看到了一些传纪类的书《小兵张嘎》《铁道游击队》还有一些国外的故事书，名字不太记得了，但是故事都很好，印象比较深的是有一个是把玻璃的知识写到了一个童话故事中。如今伯父因为一次意外已经不在了，想来不胜伤感。 成长上了初中可以看得书籍开始变多了，语文老师也会鼓励大家看一些优秀的名著。这个阶段陆续看了《朝花夕拾》《骆驼祥子》《鲁滨逊漂流记》《格列佛游记》《家春秋》《四世同堂》《老人与海》等一些书，很多书看得并不太懂，当时看这些书大多只是因为他们是名著吧，不知道现在再读会有什么新的感想。 所幸爸爸妈妈并不怎么限制我读课外书，有时还会主动给我买一些，陆续让爸妈给买了四大名著来读《西游记》《水浒传》《三国演义》《红楼梦》，当时最喜欢的是《三国演义》，读罢写了一篇作文《蜀相》参加作文比赛获得了二等奖。 初中因为离家比较远，开始住校了，也开始有了自己的零花钱，然后每隔一两个星期我就会去学校的书店买课外书看，有时候和同学约着分别买不同的书，换着看。 这个时候开始迷上了金庸古龙，飞雪连天射白鹿，笑书神侠倚碧鸳，整个初高中，把金庸的小说看了不止一遍。古龙的小说风格和金庸完全不一样，然后数量也更多，印象比较深的有《楚留香传奇》《小李飞刀》《大地飞鹰》《流星蝴蝶剑》《七种武器》《陆小凤传奇》等，看的很多，忘得也多。千古书生侠客梦，金庸古龙伴随着他们给我们创造的武侠世界，应该也是70、80年代的一个整体时代记忆吧。 记得班上有一本韩寒的《三重门》，读完之后特别想读韩寒其它的书，由于没有买到，只得作罢。 初中的宿舍一晚上都不熄灯，我正好在上铺，灯下面，很多书都是趴在床上看完的，还得时刻提防查宿的老师。 高中以前的暑假是读书最好的时光，我家自小便没有地，下午的时候，搬一把椅子，坐在阴凉地，一读便是一整天。 这个时候也开始看一些历史传记，从哥哥家找来的《隋唐演义》《杨家将》《齐白石传》《周恩来传》《洪武皇帝朱元璋》等，上下五千年，瀚如烟海。 高中高中到了泰安去上学，自己能掌握的生活费更多了，然后也就有了更多的钱去买书看，从我们学校往西走有一个夜市，有一些卖书的书摊，大部分都是一些盗版的书，合集比较多，一本书很厚，字也特别小，但是对于学生来说价格相对合适，我在那边买过很多，由于大部分是盗版，大部分书到现在也都遗失了。 初中想读而没有读到的韩寒和郭敬明也是在这里买的，读了《三重门》《零下一度》《通稿2003》《梦里花落知多少》《幻城》《夏至未至》，不一样的作者，不一样的文字，不一样的人生，也讲述不一样的故事。而今郭敬明做了导演，吸金无数，韩寒做了赛车手。匆匆十几年，弹指一挥间。 这个时候也开始接触了一些外国文学，《巴黎圣母院》《茶花女》《双城记》《堂吉诃德》，最喜欢的当属《基督山伯爵》，快意恩仇，执剑江湖。 我读书读完一本，如果喜欢就会找这本书作者的其它书来读，一本好书，往往一开始会读的特别快，临到最后反而舍不得读完。读罢，故事里面的人和事，萦萦于脑畔，飘着飘着，慢慢的尘封于一处。 语文老师上课的时候给我们推荐了余华的《活着》，读完思绪良久，又买了一本余华文集，然后读了《许三观卖血记》《在细雨中呼喊》。然后从这开始喜欢看一些近现代文学。 张爱玲的《半生缘》《金锁记》《倾城之恋》，看张爱玲的文字很容易被吸引，穿越时空回到那个时候的旧上海去旁观一个又一个的故事，在书中演绎着一个又一个各自不同的人生。 余秋雨的《千年一叹》，看余秋雨的书感觉就很博学，总是能看到很多自己不知道的东西。 巴金的《家春秋》，这三本书读起来和《红楼梦》是有一点像的，都是大家族的盛衰，看到最后沧海桑田，世事变迁。其实每个人又何尝不是如此，如今每次回老家，路过破败的老屋，看到已经不属于自己的新屋，再也找不回的儿时伙伴，心里也不胜感叹。 《红楼梦》应该是我最喜欢的文学类书籍，最早接触是在初中，当时并没有看完，高中的时候看完了一遍，深陷其中，又读了刘心武的《刘心武揭秘红楼梦》周汝昌关于红学的系列书籍，记得还有一本《红楼真梦》，高中语文课老师让同学上去分享四大名著，我便上去分享了《红楼梦》不同于其它同学，讲了一些红学和曹雪芹特殊的写作手法，备受老师和同学的赞赏。毕业后来了北京，找了个周末去了趟北京的大观园，可惜很难和书中的大观园产生共鸣。直到现在，每隔几年都会重读一次红楼梦，每次又都有新的收获，看到不同的版本，总会有收藏的欲望。最近在看白先勇老师的《细说红楼梦》，收货颇多。 贾平凹的《废都》《高老庄》，贾平凹的文字当时读不太懂，也不是特别吸引，我所以就只看过这两本，硬着头皮看，讲的什么现在也都记不得了。 《穆斯林的葬礼》是我非常喜欢的另外一本书，不同于其他书籍的叙事风格，带你走进一个穆斯林的世界。 三毛的作品也是在这个时候接触，《哭泣的骆驼》《沙哈拉的故事》《梦里花落知多少》，到后来大学毕业买了三毛全集，三毛的文字总能带给我很多感动，娓娓道来，没有太多华丽的语言却都很真实。现在仿佛感觉她还是一个人在流浪着。 高中的作文如果写的不错会被老师印做范文，在级部中讲评，我的几篇作文也被老师选中，可惜原文都没有留下来了。当时的周记也都遗失了。 大学我们大学的图书馆建的非常漂亮，曾获得过鲁班奖，整体圆弧形的设计，从前面看像一本展开的书页，图书馆的前面是人工湖，后面是大片的草坪。我当时很喜欢去图书馆借书看，说实话，文学区好书并不是很多，大部分很旧，而且热门的书籍通常借不到。偶尔遇到一本，我也很少借出去，大都是一读起来便停不下了，从上午看到晚上，一本书也差不多就看完了。 初读《平凡的世界》对我的人生观和价值观都产生了很大的影响，相逢恨晚。少平的经历或多或少给我了我很多勇气，促使我在那些独自学习的夜晚，虽然看不到未来的方向，依然默默的坚持。 莫言的书也是在这个时候看的，当时莫言还没有得诺贝尔奖，记得有次去我们学校开讲座。《红高粱》《檀香刑》因为讲的是山东的故事，所以有些时候也倍感亲切。 高中以前买的书大部分都是盗版的，而且很多都是合集，字特别小，看的时间长很毁眼睛。大学的时候开始用手机看电子书，看的书类型也更广了。 大学看技术书和专业书相对多一点，其它就是为了消磨时间看了一些《鬼吹灯》等热门的网络文学。 毕业之后初读东野圭吾又是另外一片天地，最早读的《嫌疑犯X的献身》而后看了《白夜行》《解忧杂货铺》都能带来不一样的体验。 最早知道刘心武是高中读《红楼梦》的时候，当时买了很多研究红楼梦的书，而后看了《钟鼓楼》，由于是在北京，听着书中娓娓道来的后海，随着时间的流逝，感受北京和历史的厚重。 《读库》最早是在大学实验室接触的，最早的一本读库是刘老师拿到实验室的，而后一发不可收拾，如今大半个书架都摆满了读库出品的各种书。编剧张立宪江湖人称六哥，十年间不忘初心。 沈复的《浮生六记》一本小书，读过之后感触颇深，现存的总共只有四篇，读的文言文原版，最近出了一本白话版的，读起来却很难有古文的感觉，所以还是推荐读原文。 齐邦媛的《巨流河》一部家国苦难史，战争，苦难，时代变迁，沧海桑田，斗转星移。 野夫的书风格又是不一样，有着江湖人的豪迈，还有那个时代无需过多渲染就能打动人的人和事。《乡关何处》《身边的江湖》《1980年代的爱情》每一本书都值得一看。 柴静的《看见》，媒体人的语言，不带个人情感的给我们讲述她所看见的。很喜欢柴静的人和文字，后来发现读库每年的见面会六哥都会请柴静去做主持，一直想去趟现场，结果到现在也没有去成，而今柴姑娘已经不主持了。 最近一两年看了一些最近出的书《人类简史》《未来简史》是少有的值得推荐给其它所有人的书。读过《人类简史》感觉不过瘾又找来了《枪炮、疾病与革命》。 吴晓波的新书《腾讯传》读来会感觉到我们正在经历着最近的历史，或则你也能在创造者历史，十几年的时间，腾讯的发展历程，其中的波折和故事，又有几个人能讲的清全貌。 而后看了吴军老师三册的《文明之光》，感叹人类生命在整个浩瀚宇宙之渺小，整个人类历史又是如此短暂。近现代文明对文艺复兴有了更深刻的认识，也想更多的去了解关于那段历史。 最近买了威尔杜兰特的《世界的文明》，一个人50年，不知道何时自己可以读完。 后记大部分是文学书的一些记忆，很多书在历次搬家中都遗失掉了，有时候记起来读书的过程也是一段美好的记忆。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[{"name":"读书","slug":"读书","permalink":"http://yoursite.com/tags/读书/"}]},{"title":"简化markdown写作中的贴图流程","slug":"简化markdown写作中的贴图流程","date":"2015-11-13T08:02:00.000Z","updated":"2017-09-20T01:21:29.000Z","comments":true,"path":"2015/11/13/简化markdown写作中的贴图流程/","link":"","permalink":"http://yoursite.com2015/11/13/简化markdown写作中的贴图流程/","excerpt":"","text":"一直很喜欢用markdown写文章，但是在markdown中贴图很麻烦，记得最早的时候我会将图片保存到本地，然后在markdown中使用相对路径显示。后来可以将图片放到图床上，然后在文档中使用链接。 最早一直使用ST写markdown的文档然后用了一段时间为知笔记再后来发现了这篇文章 http://tianweishu.com/2015/10/16/simplify-the-img-upload-in-markdown/ 结合自己的实践，记录一下实现方案1、申请七牛的账号，这个就不多说了，这里给七牛做一个广告，标准版10G空间，API也简单好用,传送门2、创建 Alfred 工作流，实现流程的自动化 先放一个完成后的效果图： 简单的步骤就是： 创建一个 trigger，快捷键自己设置 创建一个 run script，选择语言为 python 创建一个 output 可以设置一个系统提醒，在完成之后右上角提示。 run script 的脚本如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970query = \"&#123;query&#125;\"# -*- coding: utf-8 -*-import osimport timefrom qiniu import Auth, put_filefrom AppKit import NSPasteboard, NSPasteboardTypePNG, NSPasteboardTypeTIFFaccess_key = '你自己的 AK' # AKsecret_key = '你自己的 SK-3' # SKbucket_name = 'lepfinder-wiki' # 七牛空间名q = Auth(access_key, secret_key)def upload_qiniu(path): ''' upload file to qiniu''' dirname, filename = os.path.split(path) key = 'markdown/%s' % filename # upload to qiniu's markdown dir token = q.upload_token(bucket_name, key) ret, info = put_file(token, key, path, check_crc=True) return ret != None and ret['key'] == keydef get_paste_img_file(): pb = NSPasteboard.generalPasteboard() data_type = pb.types() # if img file print data_type now = int(time.time() * 1000) # used for filename if NSPasteboardTypePNG in data_type: # png data = pb.dataForType_(NSPasteboardTypePNG) filename = '%s.png' % now filepath = '/tmp/%s' % filename ret = data.writeToFile_atomically_(filepath, False) if ret: return filepath elif NSPasteboardTypeTIFF in data_type: # tiff data = pb.dataForType_(NSPasteboardTypeTIFF) filename = '%s.tiff' % now filepath = '/tmp/%s' % filename ret = data.writeToFile_atomically_(filepath, False) if ret: return filepath elif NSPasteboardTypeString in data_type: # string todo, recognise url of png &amp; jpg passif __name__ == '__main__': url = \"http://7xo9p3.com1.z0.glb.clouddn.com/markdown\" img_file = get_paste_img_file() if img_file: # has file ret = upload_qiniu(img_file) if ret: # upload success name = os.path.split(img_file)[1] markdown_url = \"![](%s/%s?imageMogr2/thumbnail/!50p/quality/100!)\" % (url, name) # make it to clipboard os.system(\"echo '%s' | pbcopy\" % markdown_url) os.system('osascript -e \\'tell application \"System Events\" to keystroke \"v\" using command down\\'') else: print \"upload_failed\" else: print \"get img file failed\" 使用方法 command + control + shift + 4 完成截图 command + control + shift + V 完成图片上传到七牛 command + V 粘贴外链地址到指定位置（如果光标此时在编辑器中，这一步其实是自动的）","categories":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/tags/工具/"},{"name":"markdown","slug":"markdown","permalink":"http://yoursite.com/tags/markdown/"}]},{"title":"意料之外的大雪","slug":"snow","date":"2013-03-19T16:00:00.000Z","updated":"2017-09-14T10:43:48.000Z","comments":true,"path":"2013/03/20/snow/","link":"","permalink":"http://yoursite.com2013/03/20/snow/","excerpt":"","text":"进入三月，北京的天气本来已经开始转暖，屋里的冷气也在这几天停止了供暖，有几天气温已经接近二十度，没想到从昨天中午开始，天却起了大雪，说是鹅毛大雪倒也不为过，下午下班的时候还在下雨加雪，我因为没有带伞，所以想等着小一点再走，一直到晚上8点反而越下越大。找了把同事的旧伞，凑合还可以用，就出门准备回去了，路上行人仍然不少，都是行色匆匆，估计都是下班往家里赶的人。我平时都是走路回家，大约30多分钟，今天由于天气不怎么好所以就坐公交回去，等车的时候一个女孩也没有带伞，一直在打电话。 今天早上起来推开门，才发现路上竟然积起了20厘米左右的雪，雪很白很软，树上挂满了晶光闪闪的雪花，一片银装素裹的世界。很多人在路边拍照，倒有了一种寒冬初雪的气氛。 已经有好多年不曾看到很厚又很白的雪，特别是最近很多年在外求学，大都是在城市里面，下雪的时候要么雪量很少，要么下了也就化掉了，要么就是根本没有时间和心情去外面赏雪玩雪。 上大一的时候，南方来的同学大都很期待冬天快点到来，因为可以看到雪，有些人可能从小到大都没有见过雪的世界是什么样子。不过那一年虽然雪也下了，但是赶上了多年不遇的大雪灾，南方受灾更为严重，过年回家家里下的雪一点也不比北边要少。记得我坐长途客车回去路上遇上好几个事故。 走在去公司的路上，还不是上班高峰，洁白的雪，踩上去沙沙作响，突然间就希望把自己想象成10几年前小学的时候下雪天去学校的场景，那时候天一下雪学校就会广播，让离家近的同学回家拿扫雪的工具，整个学校也开始集体大扫除，本是少年爱玩的年纪，扫雪的时候大家便免不了打打闹闹，然后校园里就会多上几个大雪堆和奇形怪状的雪人。记忆中那个时候天总是很蓝，雪也是洁白洁白。 不像城市，农村里面大片的农田，冬天下雪后很难化掉，一般会保留很长一段时间，极目望去，远山和一望无际的原野，到处都是洁白的雪，置身与其中，别有一番意境。 最近北京雾霾的天气越来越多，走在街上呼吸的空气都有一种沉重感，每次雨雪或大风过后空气会恢复过来一点，再隔一两日则又会变成昏昏暗暗的天气，真的希望有时候人可以慢一点下来，看看路边的风景，品味下静静的生活。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[{"name":"大雪","slug":"大雪","permalink":"http://yoursite.com/tags/大雪/"}]},{"title":"追忆似水流年","slug":"childhood","date":"2013-03-11T16:00:00.000Z","updated":"2017-09-14T12:38:54.000Z","comments":true,"path":"2013/03/12/childhood/","link":"","permalink":"http://yoursite.com2013/03/12/childhood/","excerpt":"","text":"现在回想起来，儿时的记忆真的是最值得珍藏的一段时光，很多东西也都已经模糊不全，留下的只有一些片段，几点画面，但即使如此，淡忘的或许永远想不起，而留下的也将一直记着无法抹去。 西池塘小时候居住的村子叫“李所村”，地处丘陵，两面环山，村子的西边有一个很大的池塘，有一口很大的泉眼，据说是从北面山上过来的水源，夏天汛期水量尤足。向南则一条小河首先向东，途径学校，直贯南北，流经村中间的时候又有几眼泉，清而洌，水质自然也是极好，河边一口老井，方一平有余，石砌而成，深不足十米，经年不曾干涸，村中人多半饮此水为生，或挑或担，或用水车，每逢朝晚，络绎不绝。 河边多树，夏日凉风习习，绿影斑驳，多有姑婆河边洗衣，家常里短，喧闹声不绝于耳。几多顽童，嬉与水间，捕鱼戏水，无不尽兴而归，全身尽湿。 村里人管东西朝向的这一段小河叫做“下沟”，沟的北面则称为“沟北沿（崖）”，我的家便在村子的最北边，本是多年老屋，大部分的石头都不是整块的，听奶奶说是当时爷爷一点一点捡碎石垒起来的。后来大约上三年级的时候就在村子的东边盖了后来的新房子，之前的老屋也拆掉了。 苹果园村子的北边是一条水渠，顺着水渠的方向则是大片的苹果园，姑姑家跟我们在一个村里，那个时候姑姑家里承包了其中的一片苹果园，有的时候我就会和儿时伙伴一起去那个地方玩耍，现在想来，倒留下很多记忆。每年的四五月份是苹果开花的季节，很淡雅的白色，微带一些红色，置身与其中，微风阵阵，一股清香，自有一番乐趣。 苹果大约在10月份左右成熟，苹果快成熟的时候就需要有人看着，防止有人偷，在苹果园里有一间屋子，平时的时候表哥会在那边看苹果园，有些时候我也会过去，游荡与满是果子的果园，又红又大的苹果触手可及。很难想象一棵苹果树怎么会结那么多果子，很多枝条被压的弯弯的。快成熟的时候，一个个红红的苹果，甚是惹人喜欢。 收苹果的时候，尤其热闹，很多人会来帮忙。诺大的苹果园仿佛进了王母娘娘的蟠桃园，红红的果子挂满枝头，在太阳下面闪着金灿灿的光。苹果按照个头大小被分别装箱，装车，运向不知道哪里的远方。 清明春游春天，万物复苏，新芽初生。小学的时候，每逢清明节，学校每年都会组织去烈士扫墓，大约提前一个多月就要准备，学校的仪仗队也会开始训练，敲鼓的、打镲的、吹号的还有举旗的，好生威武。如果能被选入仪仗队，都会被同学们羡慕。除了仪仗队的同学，其他人就要忙着训练赞歌。 等到出发的那天，大家排好队，两人一排，便浩浩荡荡的出发了，我们那个时候上学的人多，队伍都能排出两三里路。会时不时的看到有些“传令兵”小跑着传递消息，颇有些战时行军的味道。 因为是春游，午饭是要在外边解决的，吃饭的时候大家拿出各自准备的食品，分而食之，多有一番乐趣在其中。 野味在农村，地里的很多东西都是可以吃的，比如野菜、蚕蛹、蚂蚱。春天，万物复苏，路边的榆树长出榆钱，路边开出野花，长出嫩绿的野菜苗，荠菜、蓬蓬菜采一些，即使用最原始的做法，也相当的可口，最近再会老家问起家里的老人还吃么，都说大部分都有农药不敢吃了，而且村里也少了小时候的那份闲适。父辈们都在外打工，祖辈们大多年龄都大了。 收麦子在我上小学的时候我们还有“麦假”，大约一个多星期左右，因为到了麦子成熟的季节，学校的老师家里也大都有地，需要回家收麦子，然后便会给我们放假。 这个时候山上的桑葚正好成熟，和同学结伴去山上采一些，算是很好的果子了。 夏日乘凉小的时候，村子里的电视还不是特别多，每到夏天傍晚的时候，日头渐落，大家就会走出家门来到外边乘凉。有的搬一个凳子，有的拿一床凉席，手里拎一个大蒲扇，夏天由于是刚收完麦子，村里的场还没有撤掉，所以会有很多开阔的地方，地也很平整，特别适合乘凉。 邻里拉拉家常，儿童追赶嬉闹，天上的星星很多，记忆中的月亮也是又大又圆。 打牌山东人是比较喜欢打牌的，小到五六岁小孩，老到五旬老人都能够在夏日午后围坐一起，打牌聊天，可能农村的娱乐活动本来就少。我说的牌就是指纸牌，玩的花样也很多，比如入门级的“拖拉机”（“也叫排火车”），再有最常玩的”升级“，以及”保皇“”够级“，每一种玩法除了需要的人数不同，规则也是不同，所需要的牌数也不同。 小学的时候一到放寒暑假我三姑家的表哥就会来我家这边住，那时候似乎大家都很有时间，哥哥们也都在家，很容易就凑够五六个人，一起围坐一起打牌也成为那时候的一件乐事。现在除了过年大家还都会回家，再围坐一起的机会越来越少，每个人也都有了自己的家庭，也都有了孩子。 游戏机最早见过的游戏机还是表哥用弹珠“换”来的，只能玩俄罗斯方块，躲障碍之类的游戏，但是当时也玩的不亦乐乎，再后来有一天大伯父家的堂哥拿来了一个能插卡玩游戏的学习机，才第一次玩到了双截龙之类的游戏，之后便久久不能忘，过了段时间便让爸妈给买了一个那时叫“小霸王”的学习机，也算是我们80年代孩子的一个时代记忆吧。那时候在学校除了交流游戏心得，便是打听谁有新的游戏卡然后互相交换玩，“魂斗罗”“超级玛丽”“雪人兄弟”“冒险岛”“影子传说”“坦克大战”，每一个名字现在听起来还是那么有亲切。 那时候玩游戏经常是一玩一天，只能两个人一起玩，有时候人多的时候就会交替着玩，谁输了谁就下。差不多过关的游戏都会想办法通关，还记得和表哥一起把魂斗罗通关，五爷爷喜欢玩坦克，那时候我们爷俩可以玩一整天，不知爷爷是否还记得。 小学在我四年级之前还仍然在村里的小学上学，叫“李所小学”，原本是德国人在1910年左右建的教堂，在村子的最中心的位置，大小有几十间房子，有很大的院子，课件的时候异常热闹。 后来我上四年级的时候再村子的东边建了“东平成才希望小学”，有两座2层和一座3层的教学楼。这个学校是一个华侨赞助创建的，记得刚成立的时候还给我们学校的每个同学发了棉衣，文具。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[{"name":"小时候","slug":"小时候","permalink":"http://yoursite.com/tags/小时候/"}]}]}